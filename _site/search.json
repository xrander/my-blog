[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About Me",
    "section": "",
    "text": "Olamide Adu is a Data Scientist with a background in Forestry and Sustainable Nature Management. He is a graduate of the Euroforester Program from the Swedish University of Agricultural Sciences in 2023. He has a passion for Data Science and is a big lover of the R Language. He is adept at using R, loves learning and likes to give back to his community in any way he can."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "About Me",
    "section": "Education",
    "text": "Education\n\nSwedish University of Agricultural Sciences | Alnarp, Skåne, Sweden  MSc in Forest Sciences | August 2022 - Sept 2023\nUniversity of Copenhagen | Frederiksberg, Copenhagen, Denmark  MSc in Forest Sciences | August 2021 - July 2022\nThe Federal University of Technology, Akure | Akure South, Ondo, Nigeria  B. Agric. Tech. in Forestry and Wood Technology | January 2015 - December 2019"
  },
  {
    "objectID": "index.html#experiences",
    "href": "index.html#experiences",
    "title": "About Me",
    "section": "Experiences",
    "text": "Experiences\n\nSwedish University of Agricultural Sciences | Data Analyst | November 2022 - January 2023\nHP Tech Venture Group LLC | Summer Research Analyst (Externship) | January 2022 - July 2022\nFederal College of Education, Pankshin | Teaching Assistant | March 2020 - February 2021"
  },
  {
    "objectID": "index.html#languages",
    "href": "index.html#languages",
    "title": "About Me",
    "section": "Languages",
    "text": "Languages\n\nR\nPython\nJavascript"
  },
  {
    "objectID": "index.html#honors-and-awards",
    "href": "index.html#honors-and-awards",
    "title": "About Me",
    "section": "Honors and Awards",
    "text": "Honors and Awards\n\nErasmus Mundus Joint Masters Degree Scholarship (€49000) | 2021 - 2023\nDean’s List Award of Excellence | 2015 - 2019"
  },
  {
    "objectID": "posts/gef-projects/index.html",
    "href": "posts/gef-projects/index.html",
    "title": "What about our Climate Funds",
    "section": "",
    "text": "The Global Environment Facility (GEF), a partnership between the World Bank, the United Nations Environment Programme (UNEP), and the United Nations Development Programme (UNDP), plays a critical role in empowering developing countries to tackle pressing environmental issues. By providing both financial resources and technical expertise, the GEF supports these nations in implementing sustainable development practices that benefit the planet."
  },
  {
    "objectID": "posts/gef-projects/index.html#introduction",
    "href": "posts/gef-projects/index.html#introduction",
    "title": "What about our Climate Funds",
    "section": "",
    "text": "The Global Environment Facility (GEF), a partnership between the World Bank, the United Nations Environment Programme (UNEP), and the United Nations Development Programme (UNDP), plays a critical role in empowering developing countries to tackle pressing environmental issues. By providing both financial resources and technical expertise, the GEF supports these nations in implementing sustainable development practices that benefit the planet."
  },
  {
    "objectID": "posts/gef-projects/index.html#aim",
    "href": "posts/gef-projects/index.html#aim",
    "title": "What about our Climate Funds",
    "section": "Aim",
    "text": "Aim\nThis analysis delves into the GEF’s work, aiming to uncover insights through exploratory data analysis. We’ll explore key aspects like:\n\nIdentifying GEF Agencies: This will involve pinpointing the different entities involved within the GEF’s structure.\nFunding Trends: We’ll analyze trends in the total funds associated with the GEF, revealing how resources have evolved over time.\nGEF Agency Contributions: This analysis will investigate the financial contributions of each agency to the GEF’s mission.\nFocus Area Spending: We’ll assess how much funding has been allocated to the GEF’s core areas of focus (e.g., climate change, biodiversity).\nTop Recipient Countries: This exploration will identify the countries receiving the highest total project funding.\nContinental Funding Distribution: We’ll examine the top 3 funded countries within each continent, providing a more granular perspective.\nCapacity Building Investment: We’ll estimate the resources invested in building the capacity of developing countries to address environmental challenges.\nProject Status: This analysis will categorize projects based on their completion status (cancelled, approved, completed), revealing project success rates.\nProject Spending by Size and Stage: We’ll investigate how funding is distributed across projects of different sizes and stages (e.g., enabling activity and so on).\nTotal Funds Per GEF Replenishment Period: This analysis will explore how much funding was available during each GEF replenishment cycle. The GEF operates on a cycle where donor countries pledge contributions every four years. Examining trends in total funds across these periods can reveal changes in donor commitment and resource availability for the GEF’s work.\nPinpoint the Single Most Funded Project: This investigation will identify the individual project that has garnered the highest total funding from the GEF."
  },
  {
    "objectID": "posts/gef-projects/index.html#explore-data",
    "href": "posts/gef-projects/index.html#explore-data",
    "title": "What about our Climate Funds",
    "section": "Explore Data",
    "text": "Explore Data\nLet’s start by loading the data.\n\n\nShow the code\nlibrary(pacman)\np_load(\n  tidyverse, janitor, gt, countrycode, scales, ggimage, ggthemes,\n  ggtext, magick, ggtextures, gtExtras\n)\n\ntheme_set(theme_hc() +\n  theme(\n    axis.title.y = element_text(angle = 90),\n    plot.title = element_text(face = \"bold\", size = 15),\n  )\n)\n\n\n\n\nShow the code\ngef &lt;- read_csv(\"projects.csv\") |&gt; clean_names() |&gt; \n  filter(approval_fy &gt;= 1991)\n\ncol_names &lt;- str_to_upper(str_replace_all(names(gef), \"_\", \" \"))\n\nhead(gef, n = 1) |&gt; \n  gt() |&gt; \n  cols_label(\n    title = col_names[1],\n    id = col_names[2],\n    countries = col_names[3],\n    focal_areas = col_names[4],\n    type = col_names[5],\n    agencies = col_names[6],\n    gef_grant = col_names[7],\n    cofinancing = col_names[8],\n    status = col_names[9],\n    approval_fy = col_names[10],\n    funding_source_indexed_field = col_names[11],\n    non_grant_instrument_indexed_field = col_names[12],\n    capacity_building_initiative_for_transparency = col_names[13],\n    gef_period = col_names[14]\n  ) |&gt; \n  tab_header(md(\"**GEF Data Preview**\")) |&gt; \n  fmt_currency(columns = gef_grant, currency = \"USD\") |&gt; \n  tab_style(\n    style = cell_text(size = px(12)),\n    locations = cells_body(columns = everything())\n  ) |&gt; \n  tab_style(\n    style = cell_text(size = px(14)),\n    locations = cells_column_labels(columns = everything())\n  ) |&gt; \n  cols_width(\n    title ~ px(250),\n    agencies ~ px(260),\n    everything() ~ px(50)\n  ) |&gt; \n  gt_theme_538()\n\n\n\n\n\n\n\n\nGEF Data Preview\n\n\nTITLE\nID\nCOUNTRIES\nFOCAL AREAS\nTYPE\nAGENCIES\nGEF GRANT\nCOFINANCING\nSTATUS\nAPPROVAL FY\nFUNDING SOURCE INDEXED FIELD\nNON GRANT INSTRUMENT INDEXED FIELD\nCAPACITY BUILDING INITIATIVE FOR TRANSPARENCY\nGEF PERIOD\n\n\n\n\nFirst and Second Biennial Transparency Report and Fifth National Communication (1BTR + 5NC & 2BTR)\n11649\nTogo\nClimate Change\nEnabling Activity\nUnited Nations Development Programme\n$1,233,000.00\nNA\nProject Approved\n2024\nGEF Trust Fund\nNo\nNo\nGEF - 8"
  },
  {
    "objectID": "posts/gef-projects/index.html#agencies-supporting-the-gef",
    "href": "posts/gef-projects/index.html#agencies-supporting-the-gef",
    "title": "What about our Climate Funds",
    "section": "Agencies Supporting the GEF",
    "text": "Agencies Supporting the GEF\n\n\nShow the code\ngef &lt;- gef |&gt; \n  select(-c(id, non_grant_instrument_indexed_field))\n\nicons &lt;- list.files(\"agencies\", full.names = TRUE)\nagencies_abr &lt;- c(\n  \"AFDB\", \"ADB\", \"BBF\", \"Con Int\", \"DBLA\", \"DBSA\",\n  \"EBRD\", \"FAO\",\"FECO\", \"GEF\", \"IADB\", \"IFC\", \"IFAD\",\n  \"IUCN\", \"MEPC\", \"WB\", \"UNDP\", \"UNEP\", \"UNIDO\",\n  \"WADB\", \"WWF\"\n)\n\nagencies &lt;- gef |&gt; \n  select(agencies) |&gt; \n  separate_longer_delim(agencies, delim = \",\") |&gt; \n  mutate(\n    agencies = str_trim(agencies)\n  ) |&gt; \n  distinct() |&gt; \n  arrange(agencies) \n\nagencies &lt;- agencies |&gt;  \n  bind_cols(list(agencies_abr, icons)) |&gt; \n  set_names(c(\"agencies\", \"abbr\", \"logo\"))\n  \nagencies |&gt; \n  relocate(logo) |&gt; \n  gt() |&gt; \n  cols_label(\n    agencies = \"Partners\",\n    abbr = \"Abbreviation\",\n    logo = \"\"\n  ) |&gt; \n  tab_header(\n    title = \"AGENCIES SUPPORTING GEF\"\n  ) |&gt; \n  text_transform(\n    fn = function(x){\n      local_image(\n        filename = icons,\n        height = 50\n      )\n    },\n    locations = cells_body(\n      columns = logo\n    )\n  ) |&gt; \n  cols_align(\n    columns = logo,\n    align = \"center\"\n  ) |&gt; \n  gt_theme_538()\n\n\n\n\nTable 1: Partner organizations (Agencies) of the Global Environment Facility\n\n\n\n\n\n\n\n\n\nAGENCIES SUPPORTING GEF\n\n\n\nPartners\nAbbreviation\n\n\n\n\n\nAfrican Development Bank\nAFDB\n\n\n\nAsian Development Bank\nADB\n\n\n\nBrazilian Biodiversity Fund\nBBF\n\n\n\nConservation International\nCon Int\n\n\n\nDevelopment Bank of Latin America\nDBLA\n\n\n\nDevelopment Bank of Southern Africa\nDBSA\n\n\n\nEuropean Bank for Reconstruction and Development\nEBRD\n\n\n\nFood and Agriculture Organization\nFAO\n\n\n\nForeign Economic Cooperation Office\nFECO\n\n\n\nGEF Secretariat\nGEF\n\n\n\nInter-American Development Bank\nIADB\n\n\n\nInternational Finance Corporation\nIFC\n\n\n\nInternational Fund for Agricultural Development\nIFAD\n\n\n\nInternational Union for Conservation of Nature\nIUCN\n\n\n\nMinistry of Environmental Protection of China\nMEPC\n\n\n\nThe World Bank\nWB\n\n\n\nUnited Nations Development Programme\nUNDP\n\n\n\nUnited Nations Environment Programme\nUNEP\n\n\n\nUnited Nations Industrial Development Organization\nUNIDO\n\n\n\nWest African Development Bank\nWADB\n\n\n\nWorld Wildlife Fund - US Chapter\nWWF"
  },
  {
    "objectID": "posts/gef-projects/index.html#trend-of-gef-funds-since-establishment-in-1991",
    "href": "posts/gef-projects/index.html#trend-of-gef-funds-since-establishment-in-1991",
    "title": "What about our Climate Funds",
    "section": "Trend of GEF Funds since establishment in 1991",
    "text": "Trend of GEF Funds since establishment in 1991\n\n\nShow the code\ngef |&gt; \n  summarize(\n    .by = c(countries, approval_fy),\n    gef_grant = sum(gef_grant, na.rm = TRUE),\n    cofinancing = sum(cofinancing, na.rm = TRUE)\n  ) |&gt; \n  pivot_longer(\n    cols = gef_grant:cofinancing,\n    names_to = \"fund_type\",\n    values_to = \"amount\"\n  ) |&gt; \n  filter(amount &gt; 0) |&gt; \n  summarize(\n     .by = c(fund_type, approval_fy),\n     amount = sum(amount)\n  ) |&gt; \n  mutate(\n    fund_type = case_when(\n      fund_type == \"gef_grant\" ~ \"GEF\",\n      fund_type == \"cofinancing\" ~ \"Other Institutions\"\n    )\n  ) |&gt; \n  ggplot(aes(approval_fy, amount/1e6, col = fund_type, fill = fund_type)) +\n  geom_line(width = .5) +\n    geom_rect(\n    aes(xmin = 2019, xmax = 2020, ymin = 0, ymax = 11e3),\n    fill = \"gray\", size = .01, alpha = .2\n  ) +\n  geom_area(\n    position = \"dodge\",\n    alpha = .5\n  ) +\n  labs(\n    x = \"Year\",\n    y = \"Funding Amount in Million Dollars\",\n    fill = \"Funded By\",\n    col = \"Funded By\",\n    title = \"Funding Contribution from GEF and Other Bodies (1991 - 2024)\",\n    caption = \"By: Olamide Michael Adu\"\n  ) +\n  geom_vline(\n    xintercept = 1991,\n    linewidth = .3,\n    col = \"orange1\"\n  ) +\n  geom_hline(\n    yintercept = 6e3,\n    linewidth = .3,\n    col = \"orange1\"\n  ) +\n  geom_label(\n    aes(x = 1995, y = 6e3, label = \"GEF Established\"),\n    col = \"white\",\n    fill = \"tomato1\"\n  ) +\n  geom_label(\n    aes(x = 2019, y = 9e3, label = \"Covid 19\"),\n    col = \"white\",\n    fill = \"gray\"\n  ) +\n  scale_x_continuous(breaks = seq(1991, 2024, 4)) +\n  scale_y_continuous(labels = label_dollar()) +\n  scale_fill_economist() +\n  scale_color_economist() +\n  theme(\n    axis.title.y= element_text(\n      vjust = 7,\n      size = 12,\n      margin = margin(t = 0, r = 0, l = 10, b = 0)\n    ),\n    plot.margin = unit(c(.5, .5, .5, .5), \"cm\")\n  )\n\n\n\n\n\n\n\n\nFigure 1: countries with the highest fundings\n\n\n\n\n\n\nWho is responsible for financing most projects?\n\n\nShow the code\nmy_icons &lt;- tibble(\n  icons = icons,\n  agencies_abr = agencies_abr\n)\n\nmy_icons &lt;- my_icons |&gt; \n  mutate(\n    icons = paste0(\"&lt;img src =\", icons, \" width = '25'/&gt;\\ &lt;br&gt;**\", agencies_abr, \"**\")\n  )\n\ngef |&gt; \n  mutate(\n    agencies = case_when(\n      str_detect(agencies, \",\") ~ \"Multiple Organizations\",\n      .default = agencies\n    )\n  ) |&gt; \n  summarize(\n    .by = agencies,\n    fund_amount = sum(cofinancing, na.rm = TRUE)\n  ) |&gt; \n  mutate(\n    fund_amount = round(fund_amount/1e9, 1)\n  ) |&gt; \n  filter(agencies != \"Multiple Organizations\") |&gt; \n  arrange(agencies) |&gt; \n  bind_cols(my_icons[-c(9, 11, 15), ]) |&gt; # agencies not among the list removed\n  slice_max(fund_amount, n = 10) |&gt; \n  ggplot(aes(fund_amount, fct_reorder(icons, fund_amount))) +\n  geom_col(fill = \"springgreen4\") +\n  geom_label(\n    aes(label = paste0(\"$\", fund_amount, \" B\")),\n    fill = \"burlywood1\", \n    col = \"gray2\"\n  ) +\n  geom_image(aes(x = 33, y = 3, image = \"money.jpg\"), size = .7) +\n  labs(\n    title =\"Green Giants: Top Funders Backing the GEF\",\n    subtitle = \"The Key Player Behind Global Environmental Action (amount in Billions)\",\n    caption = \"By: Olamide Michael Adu\"\n  ) +\n  theme(\n    axis.title.y = element_blank(),\n    axis.text.x = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks = element_blank(),\n    axis.text.y = element_markdown(size = 9, color = \"black\"),\n    plot.subtitle = element_text(size = 11, color = \"burlywood\"),\n    plot.title = element_text(vjust = 1, hjust = -.1),\n    plot.margin = unit(c(.5, 1, .5, 1), \"cm\")\n  ) \n\n\n\n\n\n\n\n\nFigure 2: Top Environmental Players\n\n\n\n\n\nFigure 2 shows that the World Bank Group and UNDP has been the top cofinancer of GEF projects."
  },
  {
    "objectID": "posts/gef-projects/index.html#what-is-the-main-areas-that-gef-funds-go-to",
    "href": "posts/gef-projects/index.html#what-is-the-main-areas-that-gef-funds-go-to",
    "title": "What about our Climate Funds",
    "section": "What is the Main Areas That GEF Funds go to?",
    "text": "What is the Main Areas That GEF Funds go to?\n\n\nShow the code\nimage &lt;- tibble(\n  image = list(\n  image_read_svg(\"focal_areas/biodiversity.svg\"),\n  image_read_svg(\"focal_areas/chemicals_and_waste.svg\"),\n  image_read_svg(\"focal_areas/climate_change.svg\"),\n  image_read_svg(\"focal_areas/international_waters.svg\"),\n  image_read_svg(\"focal_areas/land_degradation.svg\")\n  )\n)\n\n\ngef |&gt;\n  select(gef_grant, cofinancing, focal_areas, approval_fy) |&gt; \n  replace_na(\n    list(\n      gef_grant = 0,\n      cofinancing = 0\n    )\n  ) |&gt; \n  drop_na(focal_areas) |&gt; \n  mutate(\n    total_amount = gef_grant + cofinancing,\n    .keep = \"unused\"\n  ) |&gt; \n  summarize(\n    .by = focal_areas,\n    fund_amount = sum(total_amount)\n  ) |&gt; \n  separate_longer_delim(\n    focal_areas,\n    delim = \",\"\n  ) |&gt; \n  mutate(\n    focal_areas = str_trim(focal_areas),\n    .by = fund_amount,\n    total_amount = fund_amount/n(),\n    total_amount = total_amount/1e9 # Change to billions\n  ) |&gt; \n  summarize(\n   .by = focal_areas,\n   total_amount = mean(total_amount)\n  ) |&gt; \n  arrange(focal_areas) |&gt; \n  bind_cols(image) |&gt; \n  ggplot(aes(fct_reorder(focal_areas, total_amount), total_amount, ,image = image)) +\n  geom_col(fill = \"springgreen\", alpha = .5, col = \"black\") +\n  geom_isotype_col(\n    img_height = grid::unit(1.2, \"cm\"),\n    img_width = grid::unit(1, \"cm\"),\n    ncol = 1, nrow = 1,\n    hjust = 1, vjust = .5\n  ) +\n  scale_y_continuous(breaks = seq(0, 6, 1)) +\n  labs(\n    x = \"Key Areas\",\n    y = \"Amount Invested ($ Billions)\",\n    title = \"Shifting Focus: How GEF Investment\",\n    subtitle = \"GEF Strategic Prioritization in Different Environmental Areas\",\n    caption = \"By: Olamide Michael Adu\"\n  ) +\n  coord_flip() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(hjust = -.7),\n    plot.subtitle = element_text(hjust = -1.12),\n  )\n\n\n\n\n\n\n\n\nFigure 3: The GEF focus areas spending"
  },
  {
    "objectID": "posts/gef-projects/index.html#top-funded-countries",
    "href": "posts/gef-projects/index.html#top-funded-countries",
    "title": "What about our Climate Funds",
    "section": "Top funded countries",
    "text": "Top funded countries\n\n\nShow the code\nall_funds &lt;- gef |&gt; \n  select(gef_grant, countries, cofinancing) |&gt; \n  replace_na(\n    list(\n      gef_grant = 0,\n      cofinancing = 0\n    )\n  ) |&gt; \n  mutate(\n    total_amount = gef_grant + cofinancing,\n    .keep = \"unused\"\n  ) |&gt; \n  summarize(\n    .by = c(countries),\n    total_amount = sum(total_amount)\n  ) |&gt; \n  separate_longer_delim(\n    cols = countries,\n    delim = \",\"\n  ) |&gt; \n  mutate( # This block of code is needed to find the average for countries which have been\n    countries = str_trim(countries), # grouped together during a funding round\n    .by = total_amount,\n    fund_amount = total_amount/n(),\n  ) |&gt; \n  summarize(\n    .by = c(countries),\n    total_amount = sum(fund_amount)\n  ) |&gt; \n  arrange(countries)\n\nfund_countries &lt;- all_funds |&gt; \n  filter(\n    !countries %in% c(\"Global\", \"Africa\", \"Asia/Pacific\",\n                      \"Europe and Central Asia\", \"Latin America and Caribbean\",\n                      \"Regional\"\n                      )\n  )\n\nfund_region &lt;- all_funds |&gt; \n  filter(\n    countries %in% c(\"Global\", \"Africa\", \"Asia/Pacific\",\n                      \"Europe and Central Asia\", \"Latin America and Caribbean\"\n                     )\n  )\n\n\n\n\nShow the code\ncountries &lt;- list.files(path = \"countries/svg\", full.names = TRUE)\ncountry_logo = tibble(logo = countries[str_detect(countries, \"ch|in|me|br|ph|vn|id|za|/ng|pe\")])\n\n\n\n\nShow the code\nfund_countries |&gt; \n  slice_max(total_amount, n = 10) |&gt;  \n  arrange(countries) |&gt; \n  bind_cols(country_logo) |&gt; \n  mutate( # This block ensures countries matches their logo by replacing them with abbr\n    logo = case_when(\n      str_detect(logo, \"id\") ~ str_replace(logo, \"id\", \"in\"),\n      str_detect(logo, \"in\") ~ str_replace(logo, \"in\", \"id\"),\n      str_detect(logo, \"vn\") ~ str_replace(logo, \"vn\", \"za\"),\n      str_detect(logo, \"za\") ~ str_replace(logo, \"za\", \"vn\"),\n      .default = logo\n    )\n  ) |&gt; \n  relocate(logo, .before = countries) |&gt; \n  arrange(desc(total_amount)) |&gt; \n  mutate(total_amount = round(total_amount/1e9, 2)) |&gt; \n  gt() |&gt; \n  cols_label(\n    logo = \"\",\n    countries = \"Country\",\n    total_amount = \"Funds (Billion)\"\n  ) |&gt; \n  fmt_image(\n    columns = logo, width = 30, height = 30\n  ) |&gt; \n  fmt_currency(\n    columns = total_amount\n  ) |&gt; \n  tab_header(\n    title = \"Top Funded countries with involving the GEF\",\n    subtitle = \"Funds can be by GEF, National Government and other interested parties\"\n  ) |&gt; \n  gt_theme_538()\n\n\n\n\nTable 2: Top 10 most funded countries\n\n\n\n\n\n\n\n\n\nTop Funded countries with involving the GEF\n\n\nFunds can be by GEF, National Government and other interested parties\n\n\n\nCountry\nFunds (Billion)\n\n\n\n\n\nChina\n$18.70\n\n\n\nIndia\n$7.23\n\n\n\nMexico\n$4.58\n\n\n\nBrazil\n$4.15\n\n\n\nPhilippines\n$3.85\n\n\n\nViet Nam\n$2.87\n\n\n\nIndonesia\n$2.83\n\n\n\nSouth Africa\n$2.43\n\n\n\nNigeria\n$2.19\n\n\n\nPeru\n$2.08"
  },
  {
    "objectID": "posts/gef-projects/index.html#most-funded-countries-in-each-continent",
    "href": "posts/gef-projects/index.html#most-funded-countries-in-each-continent",
    "title": "What about our Climate Funds",
    "section": "Most Funded Countries in Each Continent",
    "text": "Most Funded Countries in Each Continent\n\n\nShow the code\ncontinent &lt;- codelist |&gt; \n  select(continent, country.name.en)\n\nfund_countries &lt;- fund_countries |&gt; \n  left_join(continent, join_by(countries == country.name.en))\n  \neurope &lt;- c(\"Bosnia-Herzegovina\", \"Czech Republic\", \"Kosovo\",\n            \"Russian Federation\", \"Slovak Republic\", \"Türkiye\")\nafrica &lt;- c(\"Cabo Verde\", \"Congo\", \"Congo DR\", \"Cote d'Ivoire\",\n            \"Sao Tome and Principe\")\nasia &lt;- c(\"Korea DPR\", \"Kyrgyz Republic\", \"Lao PDR\", \"Myanmar\", \n          \"Palestinian Authority\", \"Republic Of Korea\",\n          \"Republic Of Korea\", \"Viet Nam\")\namericas &lt;- c(\"Antigua And Barbuda\", \"St. Kitts And Nevis\",\n              \"St. Vincent and Grenadines\", \"Trinidad and Tobago\")\noceania &lt;- c(\"Timor Leste\", \"Micronesia\")\n\nfund_countries &lt;- fund_countries |&gt; \n  filter(countries != \"Yugoslavia\") |&gt; \n  mutate(\n    continent = case_when(\n      countries %in% europe ~ \"Europe\",\n      countries %in% africa ~ \"Africa\",\n      countries %in% asia ~ \"Asia\",\n      countries %in% americas ~ \"Americas\",\n      countries %in% oceania ~ \"Oceania\",\n      .default = continent\n    )\n  )\n\n\n\n\nShow the code\nfund_countries |&gt; \n  group_by(continent) |&gt; \n  slice_max(total_amount, n = 3) |&gt; \n  ungroup() |&gt; \n  mutate(\n    continent = str_to_upper(continent),\n    total_amount = round(total_amount/1e6, 2)\n  ) |&gt; \n  gt(groupname_col = \"continent\") |&gt; \n  tab_header(\n    title = \"Top Funded GEF (Co)Financed Countries per Continent\"\n  ) |&gt; \n   cols_label(\n     countries = \"Country\",\n     total_amount = \" Funds Received (millions)\"\n  ) |&gt; \n  fmt_currency(\n    columns = total_amount\n  ) |&gt; \n  gt_theme_538()\n\n\n\n\nTable 3: Top Funded Countries Per Continent\n\n\n\n\n\n\n\n\n\nTop Funded GEF (Co)Financed Countries per Continent\n\n\nCountry\nFunds Received (millions)\n\n\n\n\nAFRICA\n\n\nSouth Africa\n$2,427.83\n\n\nNigeria\n$2,192.91\n\n\nEgypt\n$1,989.42\n\n\nAMERICAS\n\n\nMexico\n$4,582.48\n\n\nBrazil\n$4,146.98\n\n\nPeru\n$2,080.64\n\n\nASIA\n\n\nChina\n$18,700.05\n\n\nIndia\n$7,231.04\n\n\nPhilippines\n$3,851.19\n\n\nEUROPE\n\n\nRussian Federation\n$1,807.13\n\n\nTürkiye\n$1,505.62\n\n\nUkraine\n$937.76\n\n\nOCEANIA\n\n\nTimor Leste\n$527.64\n\n\nPapua New Guinea\n$473.85\n\n\nSolomon Islands\n$424.47"
  },
  {
    "objectID": "posts/gef-projects/index.html#what-about-capacity-building",
    "href": "posts/gef-projects/index.html#what-about-capacity-building",
    "title": "What about our Climate Funds",
    "section": "What about Capacity Building",
    "text": "What about Capacity Building\n\n\nShow the code\ngef |&gt; \n  filter(capacity_building_initiative_for_transparency != \"No\") |&gt; \n  select(capacity_building_initiative_for_transparency, approval_fy,\n         \"funding_source\" = funding_source_indexed_field, cofinancing, gef_grant) |&gt; \n  replace_na(\n    list(\n      gef_grant = 0,\n      cofinancing = 0\n    )\n  ) |&gt; \n  mutate(\n    total_amount = cofinancing + gef_grant,\n    .keep = \"unused\"\n  ) |&gt; \n  select(-capacity_building_initiative_for_transparency) |&gt; \n  ggplot(aes(approval_fy, total_amount/1e6)) +\n  geom_col(aes(fill = funding_source)) +\n  scale_fill_tableau() +\n  labs(\n    x = \"Year\",\n    y = \"Amount (Million)\",\n    title = \"Investment for Capacity Building\",\n    caption = \"By: Olamide Michael Adu\"\n  ) +\n  scale_y_continuous(labels = label_dollar()) +\n  scale_x_continuous(breaks = seq(2017, 2024, 1)) +\n  facet_wrap(~funding_source, scales = \"free_x\") +\n  theme(\n    legend.position = \"none\",\n    axis.title.y = element_text(\n      vjust = 8,\n      margin = margin(t = 0, r = 0, b = 0, l = 1, unit = \"cm\")\n    ),\n    plot.margin = unit(c(.5, 1, .5, 1), \"cm\")\n  )\n\n\n\n\n\n\n\n\nFigure 4: Amount Spent on Capacity Building"
  },
  {
    "objectID": "posts/gef-projects/index.html#project-status",
    "href": "posts/gef-projects/index.html#project-status",
    "title": "What about our Climate Funds",
    "section": "Project Status",
    "text": "Project Status\n\n\nShow the code\ngef |&gt; \n  mutate(\n    status = str_remove_all(status, \"Project \")\n  ) |&gt; \n  summarize(\n    .by = c(approval_fy, status),\n    count = n()\n  ) |&gt; \n  ggplot(aes(approval_fy, count, fill = fct_reorder(status, count))) +\n  geom_col(position = \"fill\") +\n  labs(\n    x = \"Year\",\n    y = \"Proportion\",\n    fill = \"Project Status:\",\n    title = \"State of GEF Projects\",\n    subtitle = \"Higher proportion of projects are either completed or approved.\\n2020 is having 100% approval with no completed project yet\",\n    caption = \"By: Olamide Michael Adu\"\n  ) +\n  scale_y_continuous(\n    breaks = seq(0, 1, .2),\n    labels = label_percent(scale = 100)\n  ) +\n  scale_fill_wsj() + \n  theme(\n    plot.subtitle = element_text(size = 10, hjust = -.1)\n  )\n\n\n\n\n\n\n\n\nFigure 5: Project status since 1991"
  },
  {
    "objectID": "posts/gef-projects/index.html#finance-involved-in-different-project-stage-per-year",
    "href": "posts/gef-projects/index.html#finance-involved-in-different-project-stage-per-year",
    "title": "What about our Climate Funds",
    "section": "Finance involved in Different Project Stage Per Year",
    "text": "Finance involved in Different Project Stage Per Year\n\n\nShow the code\ngef |&gt; \n  summarize(\n    .by = c(approval_fy, type),\n    gef_grant = sum(gef_grant, na.rm = TRUE),\n    cofinancing = sum(cofinancing, na.rm = TRUE)\n  ) |&gt; \n  mutate(\n    total_amount = gef_grant + cofinancing,\n    .keep = \"unused\"\n  ) |&gt;\n  ggplot(aes(approval_fy, total_amount/1e6, col = type, fill = type)) +\n  geom_area(alpha = .3) +\n  labs(\n    x = \"\",\n    y = \"Funds (millions)\",\n    title = \"Financial trend of different project stage and size\",\n    caption = \"By: Olamide Michael Adu\"\n  ) +\n  scale_y_continuous(labels = label_dollar()) +\n  facet_wrap(~type, scales = \"free_y\")\n\n\n\n\n\n\n\n\nFigure 6: Trend of Funds for different project stage or type according to size\n\n\n\n\n\n\n\nShow the code\ngef |&gt; \n  replace_na(\n    list(\n      gef_grant = 0,\n      cofinancing = 0\n    )\n  ) |&gt; \n  filter(!is.na(gef_period)) |&gt; \n  mutate(\n    total_amount = gef_grant + cofinancing,\n    .keep = \"unused\"\n  ) |&gt; \n  summarize(\n    .by = c(gef_period),\n    total_amount = sum(total_amount)\n  ) |&gt; \n  mutate(\n    xmin = case_when(\n      gef_period == \"Pilot Phase\" ~ 1991,\n      str_match(gef_period, \"\\\\d\") == 1 ~ 1994,\n      str_match(gef_period, \"\\\\d\") == 2 ~ 1998,\n      str_match(gef_period, \"\\\\d\") == 3 ~ 2002,\n      str_match(gef_period, \"\\\\d\") == 4 ~ 2006,\n      str_match(gef_period, \"\\\\d\") == 5 ~ 2010,\n      str_match(gef_period, \"\\\\d\") == 6 ~ 2014,\n      str_match(gef_period, \"\\\\d\") == 7 ~ 2018,\n      str_match(gef_period, \"\\\\d\") == 8 ~ 2022,\n    ),\n    xmax = case_when(\n      gef_period == \"Pilot Phase\" ~ 1994 ,\n      str_match(gef_period, \"\\\\d\") == 1 ~ 1998,\n      str_match(gef_period, \"\\\\d\") == 2 ~ 2002,\n      str_match(gef_period, \"\\\\d\") == 3 ~ 2006,\n      str_match(gef_period, \"\\\\d\") == 4 ~ 2010,\n      str_match(gef_period, \"\\\\d\") == 5 ~ 2014,\n      str_match(gef_period, \"\\\\d\") == 6 ~ 2018,\n      str_match(gef_period, \"\\\\d\") == 7 ~ 2022,\n      str_match(gef_period, \"\\\\d\") == 8 ~ 2026,\n    ),\n    gef_period = case_when(\n      gef_period == \"Pilot Phase\" ~ \"PP\",\n      .default = gef_period\n    )\n  ) |&gt; \n  arrange(desc(gef_period)) |&gt;\n  mutate(\n    year = c(1993, 2024, 2020, 2016, 2012, 2008, 2004, 2000, 1996)\n  ) |&gt; \n  ggplot(aes(year, total_amount/1e6)) +\n  geom_pointrange(aes(xmin = xmin, xmax = xmax), col = \"coral2\",) +\n  geom_text(\n    aes(x = xmin, y = total_amount/1e6, label = gef_period),\n    col = \"gray17\",\n    vjust = -.5,\n    hjust = -.2\n  ) +\n  labs(\n    x = \"Years\",\n    y = \"Amount (Millions)\",\n    title = \"Donation + Expenses + Turnover of the Replenishment Periods\",\n    caption = \"By: Olamide Michael Adu\"\n  ) +\n  scale_y_continuous(labels = label_dollar()) +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(vjust = 2)\n  )\n\n\n\n\n\n\n\n\nFigure 7: Total amount of GEF’s replenishment periods"
  },
  {
    "objectID": "posts/gef-projects/index.html#most-funded-project-by-the-gef",
    "href": "posts/gef-projects/index.html#most-funded-project-by-the-gef",
    "title": "What about our Climate Funds",
    "section": "Most Funded Project by the GEF",
    "text": "Most Funded Project by the GEF\n\n\nShow the code\ngef |&gt; \n  replace_na(\n    list(\n      gef_grant = 0,\n      cofinancing = 0\n    )\n  ) |&gt; \n  mutate(total_amount = gef_grant + cofinancing) |&gt; \n  summarize(\n    .by = c(title, countries, approval_fy, status),\n    total_amount = round(sum(total_amount)/1e6, 2)\n  ) |&gt; \n  slice_max(total_amount, n = 10) |&gt;\n  mutate(\n    countries = case_when(\n      str_detect(countries, \",\") ~ \"Some African Countries\",\n      .default = countries\n    )\n  ) |&gt; \n  ggplot(aes(total_amount, fct_reorder(countries, total_amount))) +\n  geom_col(\n    aes(fill = status),\n    position = position_dodge(width = .91),\n    alpha = .7\n  ) +\n  ggrepel::geom_label_repel(\n    aes(label = str_wrap(title, width = 60), fill = status),\n    size = 2.5,\n    col = \"white\",\n    nudge_x= 7\n  ) +\n  scale_fill_stata() +\n  scale_x_continuous(labels = label_dollar()) +\n  labs(\n    x = \"Project Amount (in Millions)\",\n    y = \"Regions\",\n    title = \"Most Funded Project and their Status\",\n    caption = \"By: Olamide Michael Adu\"\n  )\n\n\n\n\n\n\n\n\nFigure 8: The GEF’s most funded project"
  },
  {
    "objectID": "posts/gef-projects/index.html#conclusion",
    "href": "posts/gef-projects/index.html#conclusion",
    "title": "What about our Climate Funds",
    "section": "Conclusion:",
    "text": "Conclusion:\nThis exploratory data analysis has provided valuable insights into the Global Environment Facility’s (GEF) work and impact. By examining various aspects like funding trends, project focus areas, and recipient countries, we’ve gained a deeper understanding of how the GEF tackles global environmental challenges. The findings presented here is limited to the data provided. Limitations included is not limited to:\n\ndifficulty stating who the specific donor nations are\ndifficulty showing how funds were transferred from each replenishment period\nProject investment income\nSuccess of projects, especially for the completed ones.\nTracking projects"
  },
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "",
    "section": "",
    "text": "My personal blog content"
  },
  {
    "objectID": "posts/option-add-use-in-tuning-different-grid-for-different-models/index.html",
    "href": "posts/option-add-use-in-tuning-different-grid-for-different-models/index.html",
    "title": "Managing Workflowset Models",
    "section": "",
    "text": "The tidymodels package is a game-changer for the R ecosystem, providing a streamlined and intuitive approach to modeling. Built on the tidyverse foundation, it offers a cohesive framework that simplifies the journey from data wrangling to robust models. What makes tidymodels stand out is its consistent workflow, reducing the learning curve for data scientists and ensuring compatibility across different modeling packages【Kuhn and Silge (2022)】.\n\n\nThe workflows package is one of the standout components of tidymodels, making the iterative machine learning process in R more manageable. By bundling model fitting and data preprocessing steps into a single coherent object, workflows simplifies the complexities of the machine learning pipeline, ensuring each step is clearly defined and reproducible. This iterative machine learning process, as covered in “Tidy Modeling with R”【Kuhn and Silge (2022)】, is illustrated below:\n\n\n\nSource: Tidy Modeling with R\n\n\n\n\n\nThe focus of this post, the workflowsets package, builds on the workflows package by extending its capabilities to handle multiple machine learning models. Since the best model for any given task is not predetermined, it’s crucial to test multiple models and compare their performances. workflowsets is designed to manage multiple workflows, making it easier to compare different modeling approaches and preprocessing strategies.\nThis blog post introduces the option_add function of the workflowsets package, which is used to control options for evaluating workflow set functions such as fit_resamples and tune_grid. For more information on this function, refer to the documentation with ?option_add.\nWe start by loading the packages we will be using for this post\n\n\nShow the code\nlibrary(pacman)\np_load(tidyverse, tidymodels, gt, finetune, bonsai)\n\n\nFor this post we’ll use the heart disease dataset from kaggle.com. A preview of the data is given Table 1\n\n\nShow the code\nheart_disease &lt;- read_csv(\"heart_disease_dataset.csv\")\n\nhead(heart_disease) |&gt; \n  gt() |&gt; \n  tab_header(\n    title = \"Heart Diseases\"\n  ) |&gt; \n  opt_stylize(\n    style = 2, \n    color = \"cyan\"\n  ) |&gt; \n  as_raw_html()\n\n\n\n\nTable 1: Data Preview\n\n\n\n\n  \n  \n\n\n\nHeart Diseases\n\n\nAge\nGender\nCholesterol\nBlood Pressure\nHeart Rate\nSmoking\nAlcohol Intake\nExercise Hours\nFamily History\nDiabetes\nObesity\nStress Level\nBlood Sugar\nExercise Induced Angina\nChest Pain Type\nHeart Disease\n\n\n\n\n75\nFemale\n228\n119\n66\nCurrent\nHeavy\n1\nNo\nNo\nYes\n8\n119\nYes\nAtypical Angina\n1\n\n\n48\nMale\n204\n165\n62\nCurrent\nNone\n5\nNo\nNo\nNo\n9\n70\nYes\nTypical Angina\n0\n\n\n53\nMale\n234\n91\n67\nNever\nHeavy\n3\nYes\nNo\nYes\n5\n196\nYes\nAtypical Angina\n1\n\n\n69\nFemale\n192\n90\n72\nCurrent\nNone\n4\nNo\nYes\nNo\n7\n107\nYes\nNon-anginal Pain\n0\n\n\n62\nFemale\n172\n163\n93\nNever\nNone\n6\nNo\nYes\nNo\n2\n183\nYes\nAsymptomatic\n0\n\n\n77\nMale\n309\n110\n73\nNever\nNone\n0\nNo\nYes\nYes\n4\n122\nYes\nAsymptomatic\n1"
  },
  {
    "objectID": "posts/option-add-use-in-tuning-different-grid-for-different-models/index.html#workflow-set",
    "href": "posts/option-add-use-in-tuning-different-grid-for-different-models/index.html#workflow-set",
    "title": "Managing Workflowset Models",
    "section": "",
    "text": "Since this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/option-add-use-in-tuning-different-grid-for-different-models/index.html#introduction",
    "href": "posts/option-add-use-in-tuning-different-grid-for-different-models/index.html#introduction",
    "title": "Managing Workflowset Models",
    "section": "",
    "text": "The tidymodels package is a game-changer for the R ecosystem, providing a streamlined and intuitive approach to modeling. Built on the tidyverse foundation, it offers a cohesive framework that simplifies the journey from data wrangling to robust models. What makes tidymodels stand out is its consistent workflow, reducing the learning curve for data scientists and ensuring compatibility across different modeling packages【Kuhn and Silge (2022)】.\n\n\nThe workflows package is one of the standout components of tidymodels, making the iterative machine learning process in R more manageable. By bundling model fitting and data preprocessing steps into a single coherent object, workflows simplifies the complexities of the machine learning pipeline, ensuring each step is clearly defined and reproducible. This iterative machine learning process, as covered in “Tidy Modeling with R”【Kuhn and Silge (2022)】, is illustrated below:\n\n\n\nSource: Tidy Modeling with R\n\n\n\n\n\nThe focus of this post, the workflowsets package, builds on the workflows package by extending its capabilities to handle multiple machine learning models. Since the best model for any given task is not predetermined, it’s crucial to test multiple models and compare their performances. workflowsets is designed to manage multiple workflows, making it easier to compare different modeling approaches and preprocessing strategies.\nThis blog post introduces the option_add function of the workflowsets package, which is used to control options for evaluating workflow set functions such as fit_resamples and tune_grid. For more information on this function, refer to the documentation with ?option_add.\nWe start by loading the packages we will be using for this post\n\n\nShow the code\nlibrary(pacman)\np_load(tidyverse, tidymodels, gt, finetune, bonsai)\n\n\nFor this post we’ll use the heart disease dataset from kaggle.com. A preview of the data is given Table 1\n\n\nShow the code\nheart_disease &lt;- read_csv(\"heart_disease_dataset.csv\")\n\nhead(heart_disease) |&gt; \n  gt() |&gt; \n  tab_header(\n    title = \"Heart Diseases\"\n  ) |&gt; \n  opt_stylize(\n    style = 2, \n    color = \"cyan\"\n  ) |&gt; \n  as_raw_html()\n\n\n\n\nTable 1: Data Preview\n\n\n\n\n  \n  \n\n\n\nHeart Diseases\n\n\nAge\nGender\nCholesterol\nBlood Pressure\nHeart Rate\nSmoking\nAlcohol Intake\nExercise Hours\nFamily History\nDiabetes\nObesity\nStress Level\nBlood Sugar\nExercise Induced Angina\nChest Pain Type\nHeart Disease\n\n\n\n\n75\nFemale\n228\n119\n66\nCurrent\nHeavy\n1\nNo\nNo\nYes\n8\n119\nYes\nAtypical Angina\n1\n\n\n48\nMale\n204\n165\n62\nCurrent\nNone\n5\nNo\nNo\nNo\n9\n70\nYes\nTypical Angina\n0\n\n\n53\nMale\n234\n91\n67\nNever\nHeavy\n3\nYes\nNo\nYes\n5\n196\nYes\nAtypical Angina\n1\n\n\n69\nFemale\n192\n90\n72\nCurrent\nNone\n4\nNo\nYes\nNo\n7\n107\nYes\nNon-anginal Pain\n0\n\n\n62\nFemale\n172\n163\n93\nNever\nNone\n6\nNo\nYes\nNo\n2\n183\nYes\nAsymptomatic\n0\n\n\n77\nMale\n309\n110\n73\nNever\nNone\n0\nNo\nYes\nYes\n4\n122\nYes\nAsymptomatic\n1"
  },
  {
    "objectID": "posts/option-add-use-in-tuning-different-grid-for-different-models/index.html#workflow",
    "href": "posts/option-add-use-in-tuning-different-grid-for-different-models/index.html#workflow",
    "title": "Managing Workflowset Models",
    "section": "Workflow",
    "text": "Workflow\nThe workflows package is one of the standout components of tidymodels, making the iterative machine learning process in R more manageable. By bundling model fitting and data preprocessing steps into a single coherent object, workflows simplifies the complexities of the machine learning pipeline, ensuring each step is clearly defined and reproducible. This iterative machine learning process, as covered in “Tidy Modeling with R”【Kuhn and Silge (2022)】, is illustrated below:\n\n\n\nSource: Tidy Modeling with R"
  },
  {
    "objectID": "posts/option-add-use-in-tuning-different-grid-for-different-models/index.html#workflowsets",
    "href": "posts/option-add-use-in-tuning-different-grid-for-different-models/index.html#workflowsets",
    "title": "Managing Workflowset Models",
    "section": "Workflowsets",
    "text": "Workflowsets\nThe focus of this post, the workflowsets package, builds on the workflows package by extending its capabilities to handle multiple machine learning models. Since the best model for any given task is not predetermined, it’s crucial to test multiple models and compare their performances. workflowsets is designed to manage multiple workflows, making it easier to compare different modeling approaches and preprocessing strategies.\nThis blog post introduces the option_add function of the workflowsets package, which is used to control options for evaluating workflow set functions such as fit_resamples and tune_grid. For more information on this function, refer to the documentation with ?option_add."
  },
  {
    "objectID": "posts/option-add-use-in-tuning-different-grid-for-different-models/index.html#short-eda",
    "href": "posts/option-add-use-in-tuning-different-grid-for-different-models/index.html#short-eda",
    "title": "Managing Workflowset Models",
    "section": "Short EDA",
    "text": "Short EDA\n\n\nShow the code\nskimr::skim_without_charts(heart_disease) |&gt; \n  gt() |&gt; \n  tab_spanner(\n    label = \"Character\",\n    columns = character.min:character.whitespace\n  ) |&gt; \n  tab_spanner(\n    label = \"Numeric\",\n    columns = starts_with(\"numeric\")\n  ) |&gt; \n  cols_label(\n    skim_type ~ \"Type\",\n    skim_variable ~\"Variable\",\n    n_missing ~ \"Missing?\",\n    complete_rate ~ \"Complete?\",\n    character.min ~ \"Min\",\n    character.max ~ \"Max\",\n    character.empty ~ \"Empty\",\n    character.n_unique ~ \"Unique\",\n    character.whitespace ~ \"Gap\",\n    numeric.mean ~ \"Mean\",\n    numeric.sd ~ \"SD\",\n    numeric.p0 ~ \"Min\",\n    numeric.p25 ~ \"25%\",\n    numeric.p50 ~ \"Median\",\n    numeric.p75 ~ \"75%\",\n    numeric.p100 ~ \"Max\"\n  ) |&gt; \n  cols_width(\n    skim_type ~ px(80),\n    everything() ~ px(70)\n  ) |&gt; \n  opt_stylize(\n    style = 2,\n    color = \"cyan\",\n  ) |&gt; \n  as_raw_html()\n\n\n\n  \n  \n\n\n\nType\nVariable\nMissing?\nComplete?\nCharacter\nNumeric\n\n\nMin\nMax\nEmpty\nUnique\nGap\nMean\nSD\nMin\n25%\nMedian\n75%\nMax\n\n\n\n\ncharacter\nGender\n0\n1\n4\n6\n0\n2\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ncharacter\nSmoking\n0\n1\n5\n7\n0\n3\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ncharacter\nAlcohol Intake\n0\n1\n4\n8\n0\n3\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ncharacter\nFamily History\n0\n1\n2\n3\n0\n2\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ncharacter\nDiabetes\n0\n1\n2\n3\n0\n2\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ncharacter\nObesity\n0\n1\n2\n3\n0\n2\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ncharacter\nExercise Induced Angina\n0\n1\n2\n3\n0\n2\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ncharacter\nChest Pain Type\n0\n1\n12\n16\n0\n4\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nnumeric\nAge\n0\n1\nNA\nNA\nNA\nNA\nNA\n52.293\n15.727126\n25\n39.00\n52.0\n66\n79\n\n\nnumeric\nCholesterol\n0\n1\nNA\nNA\nNA\nNA\nNA\n249.939\n57.914673\n150\n200.00\n248.0\n299\n349\n\n\nnumeric\nBlood Pressure\n0\n1\nNA\nNA\nNA\nNA\nNA\n135.281\n26.388300\n90\n112.75\n136.0\n159\n179\n\n\nnumeric\nHeart Rate\n0\n1\nNA\nNA\nNA\nNA\nNA\n79.204\n11.486092\n60\n70.00\n79.0\n89\n99\n\n\nnumeric\nExercise Hours\n0\n1\nNA\nNA\nNA\nNA\nNA\n4.529\n2.934241\n0\n2.00\n4.5\n7\n9\n\n\nnumeric\nStress Level\n0\n1\nNA\nNA\nNA\nNA\nNA\n5.646\n2.831024\n1\n3.00\n6.0\n8\n10\n\n\nnumeric\nBlood Sugar\n0\n1\nNA\nNA\nNA\nNA\nNA\n134.941\n36.699624\n70\n104.00\n135.0\n167\n199\n\n\nnumeric\nHeart Disease\n0\n1\nNA\nNA\nNA\nNA\nNA\n0.392\n0.488441\n0\n0.00\n0.0\n1\n1\n\n\n\n\n\n\n\n?@tbl-preview-data shows there are no missing values, so we can proceed with our analysis.\nNext, we will convert all character variables to factor data types\n\n\nShow the code\nheart_diseases &lt;- heart_disease |&gt; \n  janitor::clean_names() |&gt; \n  mutate(\n    across(where(is.character), factor),\n    exercise_hours = factor(exercise_hours),\n    stress_level = factor(stress_level),\n    heart_disease = factor(\n      heart_disease, \n      labels = c(\"No\",\"Yes\"),\n      levels = c(0, 1)\n    )\n  )\n\n\n\n\nShow the code\nGGally::ggscatmat(\n  data = heart_diseases,\n  columns = 1:ncol(heart_diseases),\n  color = \"heart_disease\",\n  alpha = .3\n)\n\n\n\n\n\n\n\n\nFigure 1: Scattered Matrix Plots of variables\n\n\n\n\n\n\n\nShow the code\nGGally::ggcorr(\n  data = heart_diseases,\n  columns = 1:ncol(heart_diseases),\n  name = expression(rho),\n  geom = \"circle\",\n  size = 3,\n  min_size = 5,\n  max_size = 10,\n  angle = -45\n) +\n  ggtitle(\"Correlation Plot of Numeric Variables\")\n\n\n\n\n\n\n\n\nFigure 2: Correlation plot of numeric variables\n\n\n\n\n\n\n\nShow the code\nheart_diseases |&gt; \n  ggplot(aes(heart_disease, fill = gender)) +\n  geom_bar(position = \"dodge\") +\n  labs(\n    x = \"Heart disease\",\n    y = \"Frequency\",\n    title = \"Heart disease a bit more prevalent in male than females\"\n  ) +\n  ggthemes::scale_fill_fivethirtyeight()\n\n\n\n\n\n\n\n\nFigure 3: Frequency of Heart Disease Outcome\n\n\n\n\n\nWe won’t spend time on EDA and proceed with our modeling workflow."
  },
  {
    "objectID": "posts/option-add-use-in-tuning-different-grid-for-different-models/index.html#modeling",
    "href": "posts/option-add-use-in-tuning-different-grid-for-different-models/index.html#modeling",
    "title": "Managing Workflowset Models",
    "section": "Modeling",
    "text": "Modeling\n\nData Splitting\nwe will split our data to 75% for training and 25% for testing, using the outcome variable (heart_disease) as the strata to ensure a balance split. Additionally, We will create validation folds to evaluate the models.\n\n\nShow the code\nset.seed(832)\nhd_split &lt;- initial_split(heart_diseases, prop = .75, strata = heart_disease)\n\nhd_train &lt;- training(hd_split)\nhd_folds &lt;- vfold_cv(hd_train)\n\nhead(hd_train) |&gt; \n  gt() |&gt; \n  opt_stylize(\n    style = 2,\n    color = \"cyan\"\n  ) |&gt; \n  as_raw_html()\n\n\n\n  \n  \n\n\n\nage\ngender\ncholesterol\nblood_pressure\nheart_rate\nsmoking\nalcohol_intake\nexercise_hours\nfamily_history\ndiabetes\nobesity\nstress_level\nblood_sugar\nexercise_induced_angina\nchest_pain_type\nheart_disease\n\n\n\n\n48\nMale\n204\n165\n62\nCurrent\nNone\n5\nNo\nNo\nNo\n9\n70\nYes\nTypical Angina\nNo\n\n\n62\nFemale\n172\n163\n93\nNever\nNone\n6\nNo\nYes\nNo\n2\n183\nYes\nAsymptomatic\nNo\n\n\n37\nFemale\n317\n137\n66\nCurrent\nHeavy\n3\nNo\nYes\nYes\n5\n114\nNo\nNon-anginal Pain\nNo\n\n\n43\nMale\n155\n169\n82\nCurrent\nHeavy\n8\nYes\nYes\nNo\n2\n163\nNo\nTypical Angina\nNo\n\n\n44\nFemale\n250\n111\n66\nFormer\nNone\n6\nYes\nNo\nYes\n3\n121\nYes\nNon-anginal Pain\nNo\n\n\n43\nFemale\n279\n173\n81\nCurrent\nModerate\n9\nYes\nNo\nNo\n7\n150\nNo\nAsymptomatic\nNo\n\n\n\n\n\n\n\n\n\nModel Specification\nWe will use two models for our analysis:\n\nK-nearest neighbors (KNN) model\nGeneralized linear model (GLM).\n\n\n\nShow the code\nknn_spec &lt;- nearest_neighbor(\n  neighbors = tune(),\n  weight_func = tune(),\n  dist_power = tune()\n) |&gt; \n  set_engine(\"kknn\") |&gt; \n  set_mode(\"classification\")\n\nglm_spec &lt;- logistic_reg() |&gt; \n  set_engine(\"glm\", family = stats::binomial(link = \"logit\")) |&gt; \n  set_mode(\"classification\")\n\n\nBelow is the specification we have set for the KNN model:\n\n\nShow the code\nknn_spec |&gt;  translate()\n\n\nK-Nearest Neighbor Model Specification (classification)\n\nMain Arguments:\n  neighbors = tune()\n  weight_func = tune()\n  dist_power = tune()\n\nComputational engine: kknn \n\nModel fit template:\nkknn::train.kknn(formula = missing_arg(), data = missing_arg(), \n    ks = min_rows(tune(), data, 5), kernel = tune(), distance = tune())\n\n\nThe KNN spec model is having three tuning parameters. For the GLM model we have the following:\n\n\nShow the code\nglm_spec |&gt; translate()\n\n\nLogistic Regression Model Specification (classification)\n\nEngine-Specific Arguments:\n  family = stats::binomial(link = \"logit\")\n\nComputational engine: glm \n\nModel fit template:\nstats::glm(formula = missing_arg(), data = missing_arg(), weights = missing_arg(), \n    family = stats::binomial(link = \"logit\"))\n\n\nThe GLM specification is having no tuning parameter.\nAs seen in all the model specification above, the formula is missing. We’ll determine the formula for all models and the necessary preprocessing/feature engineering options we want to include in the next step using the recipe package\n\n\nData Preprocessing\nWe have three preprocessing specification. The first defines the formula which we will use, the second includes normalizing all numeric predictors, and the final preprocessing step involves creating dummy variables for our categorical variables.\n\n\nShow the code\nformula &lt;- recipe(\n  heart_disease ~ .,\n  data = hd_train\n)\n\nnormalize &lt;- formula |&gt; \n  step_normalize(all_numeric_predictors())\n\ndummy &lt;- normalize |&gt; \n  step_dummy(all_factor_predictors())\n\n\n\n\nShow the code\nnormalize |&gt; \n  prep() |&gt; \n  juice() |&gt; \n  head() |&gt; \n  gt() |&gt; \n  opt_stylize(\n    style = 3,\n    color = \"cyan\"\n  )\n\n\n\n\nTable 2: Preview of normalized preprocessed data\n\n\n\n\n\n\n\n\n\nage\ngender\ncholesterol\nblood_pressure\nheart_rate\nsmoking\nalcohol_intake\nexercise_hours\nfamily_history\ndiabetes\nobesity\nstress_level\nblood_sugar\nexercise_induced_angina\nchest_pain_type\nheart_disease\n\n\n\n\n-0.2983420\nMale\n-0.784268085\n1.13748976\n-1.4962849\nCurrent\nNone\n5\nNo\nNo\nNo\n9\n-1.7689353\nYes\nTypical Angina\nNo\n\n\n0.6020865\nFemale\n-1.332244271\n1.06281212\n1.2243394\nNever\nNone\n6\nNo\nYes\nNo\n2\n1.3197224\nYes\nAsymptomatic\nNo\n\n\n-1.0058214\nFemale\n1.150772824\n0.09200285\n-1.1452366\nCurrent\nHeavy\n3\nNo\nYes\nYes\n5\n-0.5662721\nNo\nNon-anginal Pain\nNo\n\n\n-0.6199235\nMale\n-1.623356620\n1.28684503\n0.2589566\nCurrent\nHeavy\n8\nYes\nYes\nNo\n2\n0.7730573\nNo\nTypical Angina\nNo\n\n\n-0.5556072\nFemale\n0.003447684\n-0.87880642\n-1.1452366\nFormer\nNone\n6\nYes\nNo\nYes\n3\n-0.3749394\nYes\nNon-anginal Pain\nNo\n\n\n-0.6199235\nFemale\n0.500051103\n1.43620030\n0.1711946\nCurrent\nModerate\n9\nYes\nNo\nNo\n7\n0.4177250\nNo\nAsymptomatic\nNo\n\n\n\n\n\n\n\n\n\n\nTable 2 previews how the data looks after normalizing, which is the second feature engineering technique. Table 3 shows the data after creating dummy variables categorical variables.\n\n\nShow the code\ndummy |&gt; \n  prep() |&gt; \n  juice() |&gt; \n  head() |&gt; \n  gt() |&gt; \n  opt_stylize(\n    style = 2,\n    color = \"cyan\"\n  ) |&gt; \n  as_raw_html()\n\n\n\n\nTable 3: Preview of dummy + normalized preprocessed data\n\n\n\n\n  \n  \n\n\n\nage\ncholesterol\nblood_pressure\nheart_rate\nblood_sugar\nheart_disease\ngender_Male\nsmoking_Former\nsmoking_Never\nalcohol_intake_Moderate\nalcohol_intake_None\nexercise_hours_X1\nexercise_hours_X2\nexercise_hours_X3\nexercise_hours_X4\nexercise_hours_X5\nexercise_hours_X6\nexercise_hours_X7\nexercise_hours_X8\nexercise_hours_X9\nfamily_history_Yes\ndiabetes_Yes\nobesity_Yes\nstress_level_X2\nstress_level_X3\nstress_level_X4\nstress_level_X5\nstress_level_X6\nstress_level_X7\nstress_level_X8\nstress_level_X9\nstress_level_X10\nexercise_induced_angina_Yes\nchest_pain_type_Atypical.Angina\nchest_pain_type_Non.anginal.Pain\nchest_pain_type_Typical.Angina\n\n\n\n\n-0.2983420\n-0.784268085\n1.13748976\n-1.4962849\n-1.7689353\nNo\n1\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n1\n\n\n0.6020865\n-1.332244271\n1.06281212\n1.2243394\n1.3197224\nNo\n0\n0\n1\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n\n\n-1.0058214\n1.150772824\n0.09200285\n-1.1452366\n-0.5662721\nNo\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n1\n1\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n\n\n-0.6199235\n-1.623356620\n1.28684503\n0.2589566\n0.7730573\nNo\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n1\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n-0.5556072\n0.003447684\n-0.87880642\n-1.1452366\n-0.3749394\nNo\n0\n1\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n1\n0\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n1\n0\n\n\n-0.6199235\n0.500051103\n1.43620030\n0.1711946\n0.4177250\nNo\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n\n\n\n\n\n\n\n\nModel Workflow Set\n\n\nShow the code\nhd_wf_set&lt;- workflow_set(\n  preproc = list(\n    form = formula,\n    norm = normalize,\n    dum = dummy\n  ),\n  models = list(\n    glm = glm_spec,\n    knn = knn_spec\n  )\n)\n\n\n\n\nTuning Parameter\nUsing the workflowset function, we’ve tied three recipe objects to the three different models. The K-nearest neighbor model needs tuning as mentioned earlier.\n\n\nShow the code\nset.seed(34443)\n\nknn_grid &lt;- knn_spec |&gt; \n  extract_parameter_set_dials() |&gt; \n  grid_regular(levels = 6)\n\nknn_latin &lt;- knn_spec |&gt; \n  extract_parameter_set_dials() |&gt; \n  grid_latin_hypercube(size = 300)\n\ngrid_control &lt;- control_race(\n  save_pred = TRUE,\n  save_workflow = TRUE\n)\n\nknn_grid |&gt; \n  ggplot(aes(dist_power, neighbors, col = weight_func)) +\n  geom_point() +\n  ggthemes::scale_color_colorblind() +\n  labs(\n    x = \"Minkowski distance\",\n    y = \"Number of Neighbors\",\n    title = \"k-NN Regular Grid\"\n  ) +\n  facet_wrap(~weight_func) +\n  theme(\n    legend.position = \"none\"\n  )\n  \nknn_latin |&gt;\n  ggplot(aes(dist_power, neighbors, col = weight_func)) +\n  geom_point() +\n  ggthemes::scale_color_tableau() +\n  labs(\n    x = \"Minkowski distance\",\n    y = \"Number of Neighbors\",\n    title = \"k-NN Latin Hypercube Grid\"\n  ) +\n  facet_wrap(~weight_func) +\n  theme(\n    legend.position = \"none\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n(a) - knn regular tune grid - knn latin hypercube tune grid\n\n\n\n\n\n\n\n\n\n\n\n(b) - knn regular tune grid - knn latin hypercube tune grid\n\n\n\n\n\n\nFigure 4: Tuning grids to be used for K-nearest neighbor model specification\n\n\n\n\nWe set the tuning grid for the model and use the option_add function to specify it. We will test two different grid structures as shown in Figure 4."
  },
  {
    "objectID": "posts/option-add-use-in-tuning-different-grid-for-different-models/index.html#using-option_add-to-specify-model-grids",
    "href": "posts/option-add-use-in-tuning-different-grid-for-different-models/index.html#using-option_add-to-specify-model-grids",
    "title": "Managing Workflowset Models",
    "section": "Using option_add to Specify Model Grids",
    "text": "Using option_add to Specify Model Grids\nWe can specify the grid to use for each model using the option_add function. Below is an image of hd_wf_set that we defined recently, and we will interpret its output.\n\n\n\nDefined workflowset output\n\n\nThe image above shows that option column is having zero values as well as the results column.\n\n\nShow the code\nhd_tune &lt;- hd_wf_set |&gt; \n  option_add(\n    id = \"norm_knn\",\n    grid = knn_grid,\n    control = grid_control\n  ) |&gt; \n  option_add(\n    id = \"form_knn\",\n    grid = knn_grid,\n    control = grid_control\n  ) |&gt; \n  option_add(\n    id = \"norm_knn\",\n    grid = knn_latin,\n    control = grid_control\n  ) |&gt; \n  option_add(\n    id = \"form_knn\",\n    grid = knn_latin,\n    control = grid_control\n  ) |&gt; \n  option_add(\n    id = \"dum_knn\",\n    grid = knn_grid,\n    control = grid_control\n  ) |&gt; \n  option_add(\n    id = \"dum_knn\",\n    grid = knn_latin,\n    control = grid_control\n  )\n\n\n\n\n\nDefined workflowset output after options are added\n\n\nAfter using the option-add function, we can see that KNN model specification have two options added to it. We can now proceed to tune our model.\n\n\nShow the code\ndoParallel::registerDoParallel(cores = 6)\n\nhd_tune_res &lt;- workflow_map(\n hd_tune ,\n fn = \"tune_race_anova\",\n resamples = hd_folds,\n seed = 3343,\n verbose = TRUE\n)\n\n\ni   No tuning parameters. `fit_resamples()` will be attempted\n\n\ni 1 of 6 resampling: form_glm\n\n\n✔ 1 of 6 resampling: form_glm (510ms)\n\n\ni 2 of 6 tuning:     form_knn\n\n\n✔ 2 of 6 tuning:     form_knn (1m 39.3s)\n\n\ni   No tuning parameters. `fit_resamples()` will be attempted\n\n\ni 3 of 6 resampling: norm_glm\n\n\n✔ 3 of 6 resampling: norm_glm (514ms)\n\n\ni 4 of 6 tuning:     norm_knn\n\n\n✔ 4 of 6 tuning:     norm_knn (1m 46.5s)\n\n\ni   No tuning parameters. `fit_resamples()` will be attempted\n\n\ni 5 of 6 resampling: dum_glm\n\n\n✔ 5 of 6 resampling: dum_glm (646ms)\n\n\ni 6 of 6 tuning:     dum_knn\n\n\n✔ 6 of 6 tuning:     dum_knn (2m 30.6s)"
  },
  {
    "objectID": "posts/option-add-use-in-tuning-different-grid-for-different-models/index.html#tune-result",
    "href": "posts/option-add-use-in-tuning-different-grid-for-different-models/index.html#tune-result",
    "title": "Managing Workflowset Models",
    "section": "Tune Result",
    "text": "Tune Result\n\n\nShow the code\nautoplot(hd_tune_res)\n\n\n\n\n\n\n\n\nFigure 5\n\n\n\n\n\n\n\nShow the code\nhd_tune_res |&gt; \n  rank_results(rank_metric = \"accuracy\") |&gt; \n  filter(.metric == \"accuracy\") |&gt; \n  select(-c(.metric,  preprocessor, model, n)) |&gt; \n  gt() |&gt; \n  cols_label(\n    wflow_id = \"Model ID\",\n    .config = \"Model Number\"\n  ) |&gt; \n  opt_stylize(\n    style = 2,\n    color = \"cyan\"\n  ) |&gt; \n  as_raw_html()\n\n\n\n  \n  \n\n\n\nModel ID\nModel Number\nmean\nstd_err\nrank\n\n\n\n\nform_knn\nPreprocessor1_Model236\n0.8653333\n0.013546445\n1\n\n\nnorm_knn\nPreprocessor1_Model236\n0.8653333\n0.013546445\n2\n\n\nform_glm\nPreprocessor1_Model1\n0.8613333\n0.013799266\n3\n\n\nnorm_glm\nPreprocessor1_Model1\n0.8613333\n0.013799266\n4\n\n\ndum_glm\nPreprocessor1_Model1\n0.8613333\n0.013799266\n5\n\n\nnorm_knn\nPreprocessor1_Model134\n0.8520000\n0.012000000\n6\n\n\nform_knn\nPreprocessor1_Model134\n0.8520000\n0.012000000\n7\n\n\ndum_knn\nPreprocessor1_Model134\n0.7426667\n0.008899993\n8\n\n\ndum_knn\nPreprocessor1_Model137\n0.7413333\n0.009573626\n9\n\n\ndum_knn\nPreprocessor1_Model129\n0.7386667\n0.011958777\n10\n\n\ndum_knn\nPreprocessor1_Model103\n0.7360000\n0.010850272\n11\n\n\ndum_knn\nPreprocessor1_Model222\n0.7333333\n0.015267168\n12\n\n\ndum_knn\nPreprocessor1_Model106\n0.7333333\n0.008663817\n13\n\n\ndum_knn\nPreprocessor1_Model221\n0.7226667\n0.013303671\n14\n\n\n\n\n\n\n\nBased on the results, it appears that the KNN model with no preprocessing is the best performing model."
  },
  {
    "objectID": "posts/option-add-use-in-tuning-different-grid-for-different-models/index.html#conclusion",
    "href": "posts/option-add-use-in-tuning-different-grid-for-different-models/index.html#conclusion",
    "title": "Managing Workflowset Models",
    "section": "Conclusion",
    "text": "Conclusion\nThe success of our KNN model, particularly with preprocessing, underscores the critical role of the option_add function. By utilizing option_add, we efficiently defined and refined our model’s tuning grid, allowing us to systematically explore and optimize hyperparameters. This approach not only enhances model performance but also ensures robustness and reliability in our predictive analytics pipeline."
  },
  {
    "objectID": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html",
    "href": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html",
    "title": "Webscraping and Visualizing the Top CryptoCurrencies",
    "section": "",
    "text": "Cryptocurrencies have captivated the financial world, bringing immense joy to some and heartache to many. One thing is certain: when you get it right and strike gold with cryptocurrencies, it can set you up for life (depending on your frugality and investment amount). As a data scientist, I know the thrill of diving into this dynamic market.\nThis post, however, isn’t about trading strategies or price forecasting. Instead, it’s a exploring the capabilities of R in web scraping using the rvest package. Since I like to spend time in creating good visuals, I will be making some interesting visualization here."
  },
  {
    "objectID": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html#cryptocurrency-chronicles-r-emojimoney",
    "href": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html#cryptocurrency-chronicles-r-emojimoney",
    "title": "Webscraping and Visualizing the Top CryptoCurrencies",
    "section": "",
    "text": "Cryptocurrencies have captivated the financial world, bringing immense joy to some and heartache to many. One thing is certain: when you get it right and strike gold with cryptocurrencies, it can set you up for life (depending on your frugality and investment amount). As a data scientist, I know the thrill of diving into this dynamic market.\nThis post, however, isn’t about trading strategies or price forecasting. Instead, it’s a comprehensive guide for those interested in web scraping using R. Whether you’re a seasoned developer or a curious beginner, you’ll find valuable insights and practical techniques here. And if you have a passion for data visualization, you’re in for a treat. So, join me as we explore the fascinating world of cryptocurrencies through the lens of data science and R programming. {width=“250”, height=“300”}"
  },
  {
    "objectID": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html#getting",
    "href": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html#getting",
    "title": "Webscraping and Visualizing the Top CryptoCurrencies",
    "section": "Getting",
    "text": "Getting"
  },
  {
    "objectID": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html#cryptocurrency-chronicles",
    "href": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html#cryptocurrency-chronicles",
    "title": "Webscraping and Visualizing the Top CryptoCurrencies",
    "section": "",
    "text": "Cryptocurrencies have captivated the financial world, bringing immense joy to some and heartache to many. One thing is certain: when you get it right and strike gold with cryptocurrencies, it can set you up for life (depending on your frugality and investment amount). As a data scientist, I know the thrill of diving into this dynamic market.\nThis post, however, isn’t about trading strategies or price forecasting. Instead, it’s a comprehensive guide for those interested in web scraping using R. Whether you’re a seasoned developer or a curious beginner, you’ll find valuable insights and practical techniques here. And if you have a passion for data visualization, you’re in for a treat. So, join me as we explore the fascinating world of cryptocurrencies through the lens of data science and R programming."
  },
  {
    "objectID": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html#cryptocurrency-chronicles-r-emojismile",
    "href": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html#cryptocurrency-chronicles-r-emojismile",
    "title": "Webscraping and Visualizing the Top CryptoCurrencies",
    "section": "",
    "text": "Cryptocurrencies have captivated the financial world, bringing immense joy to some and heartache to many. One thing is certain: when you get it right and strike gold with cryptocurrencies, it can set you up for life (depending on your frugality and investment amount). As a data scientist, I know the thrill of diving into this dynamic market.\nThis post, however, isn’t about trading strategies or price forecasting. Instead, it’s a comprehensive guide for those interested in web scraping using R. Whether you’re a seasoned developer or a curious beginner, you’ll find valuable insights and practical techniques here. And if you have a passion for data visualization, you’re in for a treat. So, join me as we explore the fascinating world of cryptocurrencies through the lens of data science and R programming. {width=“250”, height=“300”}"
  },
  {
    "objectID": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html#getting-our-data",
    "href": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html#getting-our-data",
    "title": "Webscraping and Visualizing the Top CryptoCurrencies",
    "section": "Getting Our data",
    "text": "Getting Our data\n\nFirst, I scraped data from CoinMarketCap using the URL https://coinmarketcap.com/all/views/all/. The code extracts a specific table and selects relevant columns like name, symbol, market cap, and price.\n\n\n\nShow the code\nlibrary(pacman)\np_load(rvest, tidyverse, magick, ggimage)\n\nurl &lt;- \"https://coinmarketcap.com/all/views/all/\"\n\ncrypto &lt;- read_html(url) |&gt; \n  html_nodes(\"table\") |&gt; \n  html_table()\n\ncrypto &lt;- crypto[[3]]\n\nhead(crypto)\n\n\n# A tibble: 6 × 1,001\n   Rank Name        Symbol `Market Cap` Price `Circulating Supply` `Volume(24h)`\n  &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt; &lt;chr&gt;                &lt;chr&gt;        \n1     1 BTCBitcoin  BTC    $1.07T$1,07… $54,… 19,719,475 BTC       $52,500,564,…\n2     2 ETHEthereum ETH    $345.06B$34… $2,8… 120,196,848 ETH *    $29,468,896,…\n3     3 USDTTether… USDT   $112.44B$11… $0.9… 112,484,875,383 USD… $96,103,976,…\n4     4 BNBBNB      BNB    $69.21B$69,… $469… 147,582,870 BNB *    $2,632,825,3…\n5     5 SOLSolana   SOL    $58.11B$58,… $125… 462,886,047 SOL *    $4,203,105,4…\n6     6 USDCUSDC    USDC   $33.09B$33,… $0.9… 33,099,458,015 USDC… $9,313,268,3…\n# ℹ 994 more variables: `% 1h` &lt;chr&gt;, `% 24h` &lt;chr&gt;, `% 7d` &lt;chr&gt;, `` &lt;lgl&gt;,\n#   `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;,\n#   `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;,\n#   `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;,\n#   `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;,\n#   `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;,\n#   `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;, `` &lt;lgl&gt;, …"
  },
  {
    "objectID": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html#explore-data",
    "href": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html#explore-data",
    "title": "Webscraping and Visualizing the Top CryptoCurrencies",
    "section": "Explore Data",
    "text": "Explore Data\n\nNow that I’ve obtained the data, I can explore the data. Is the data clean?. There are a lot of columns not needed when I imported the data. I’ll use the janitor package clean_names() function to clean the name of the columns. After that, I will select the columns that are of interest.\n\n\n\nShow the code\ncrypto &lt;- crypto |&gt; \n  janitor::clean_names() |&gt; \n  select(name, symbol, market_cap, price)\n\nglimpse(crypto)\n\n\nRows: 200\nColumns: 4\n$ name       &lt;chr&gt; \"BTCBitcoin\", \"ETHEthereum\", \"USDTTether USDt\", \"BNBBNB\", \"…\n$ symbol     &lt;chr&gt; \"BTC\", \"ETH\", \"USDT\", \"BNB\", \"SOL\", \"USDC\", \"XRP\", \"TON\", \"…\n$ market_cap &lt;chr&gt; \"$1.14T$1,135,420,582,804\", \"$380.34B$380,339,921,251\", \"$1…\n$ price      &lt;chr&gt; \"$57,663.40\", \"$3,161.90\", \"$0.9989\", \"$527.81\", \"$134.56\",…\n\n\n\nIs the data structure as expected? From the data which we have above, there are some columns that needs their data types changed. The market_cap and price column should be numeric/double data type and not character.\n\n\n\nShow the code\ncrypto &lt;- crypto |&gt; \n  mutate(\n    market_cap = str_remove_all(market_cap, r\"--[\\$[\\d.]+]--\"),\n    market_cap = parse_number(market_cap),\n    price = parse_number(price)\n  )\n\nstr(crypto)\n\n\ntibble [200 × 4] (S3: tbl_df/tbl/data.frame)\n $ name      : chr [1:200] \"BTCBitcoin\" \"ETHEthereum\" \"USDTTether USDt\" \"BNBBNB\" ...\n $ symbol    : chr [1:200] \"BTC\" \"ETH\" \"USDT\" \"BNB\" ...\n $ market_cap: num [1:200] 1.35e+11 3.40e+08 3.64e+08 7.79e+08 2.72e+08 ...\n $ price     : num [1:200] 5.77e+04 3.16e+03 9.99e-01 5.28e+02 1.35e+02 ...\n\n\nIs the data complete? I will check for missing data using skimr package\n\n\nShow the code\nskimr::n_missing(crypto)\n\n\n[1] 360\n\n\n\n\nShow the code\nskimr::skim(crypto)\n\n\n\nData summary\n\n\nName\ncrypto\n\n\nNumber of rows\n200\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nname\n0\n1\n3\n37\n0\n200\n0\n\n\nsymbol\n0\n1\n0\n4\n180\n21\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nmarket_cap\n180\n0.1\n7.144855e+09\n3.019437e+10\n25386560\n174754584.75\n343609773.00\n742368903.50\n1.354206e+11\n▇▁▁▁▁\n\n\nprice\n180\n0.1\n3.098610e+03\n1.286256e+04\n0\n0.86\n5.78\n85.79\n5.766340e+04\n▇▁▁▁▁\n\n\n\n\n\nmarket_cap and price are having missing values and I will clean this to return only the complete rows and columns.\n\n\nShow the code\ncrypto &lt;- crypto[complete.cases(crypto), ]\nskimr::skim_without_charts(crypto)\n\n\n\nData summary\n\n\nName\ncrypto\n\n\nNumber of rows\n20\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nname\n0\n1\n6\n17\n0\n20\n0\n\n\nsymbol\n0\n1\n3\n4\n0\n20\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\n\n\n\n\nmarket_cap\n0\n1\n7.144855e+09\n3.019437e+10\n25386560\n174754584.75\n343609773.00\n742368903.50\n1.354206e+11\n\n\nprice\n0\n1\n3.098610e+03\n1.286256e+04\n0\n0.86\n5.78\n85.79\n5.766340e+04"
  },
  {
    "objectID": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html#data-visualization",
    "href": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html#data-visualization",
    "title": "Webscraping and Visualizing the Top CryptoCurrencies",
    "section": "Data Visualization",
    "text": "Data Visualization\n\nNow, let’s visualize the data! I created a donut chart to represent the market cap distribution of the top six cryptocurrencies. The remaining currencies are grouped into an “Other” category.\nThe code calculates the market cap share for each currency, along with cumulative values and labels for the chart.\n\n\nShow the code\ncrypto &lt;- crypto |&gt; \n  mutate(\n    new_sym = fct_lump(\n      symbol, n = 6, w = market_cap\n    )\n  )\n\ncrypto |&gt; \n  summarize(\n    .by = new_sym,\n    market_cap = sum(market_cap),\n    count = n()\n  )\n\n\n\n\nTable 1: Top Six Cryptocurrencies according to Market Capitalization\n\n\n\n# A tibble: 7 × 3\n  new_sym    market_cap count\n  &lt;fct&gt;           &lt;dbl&gt; &lt;int&gt;\n1 BTC     1071480397941     1\n2 ETH      345058510685     1\n3 USDT     112440083915     1\n4 BNB       69212448352     1\n5 SOL       58108556585     1\n6 USDC      33094885127     1\n7 Other    132042521446    14\n\n\n\n\n\nTable 1 shows that the market cap has been compressed into 7, 6 for the top cryptocurrency and 14 lumped together into a new category, Other.\n\n\n\nShow the code\ncrypto_summary &lt;- crypto |&gt; \n  summarize(\n    .by = new_sym,\n    market_cap = sum(market_cap)\n  ) |&gt; \n  mutate(\n    prop = market_cap/sum(market_cap) * 100,\n    market_cap = round(market_cap/1e9, 2),\n    market_cap = paste0(market_cap, \" B\"),\n    ymax = cumsum(prop),\n    ymin = c(0, head(ymax, n = -1)),\n    lab_pos = (ymax + ymin)/2,\n    label = paste0(new_sym, \"\\nValue: \",round(prop, 2), \"%\")\n  )"
  },
  {
    "objectID": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html#data-exploration-and-cleaning",
    "href": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html#data-exploration-and-cleaning",
    "title": "Webscraping and Visualizing the Top CryptoCurrencies",
    "section": "Data Exploration and Cleaning",
    "text": "Data Exploration and Cleaning\n\nI started by cleaning the column names using janitor::clean_names() and selecting the columns I needed. Then, I ensured data types were appropriate by converting market_cap and price to numeric values.\n\n\n\nShow the code\ncrypto &lt;- crypto |&gt; \n  janitor::clean_names() |&gt; \n  select(name, symbol, market_cap, price)\n\nglimpse(crypto)\n\n\nRows: 200\nColumns: 4\n$ name       &lt;chr&gt; \"BTCBitcoin\", \"ETHEthereum\", \"USDTTether USDt\", \"BNBBNB\", \"…\n$ symbol     &lt;chr&gt; \"BTC\", \"ETH\", \"USDT\", \"BNB\", \"SOL\", \"USDC\", \"XRP\", \"TON\", \"…\n$ market_cap &lt;chr&gt; \"$1.07T$1,071,480,397,941\", \"$345.06B$345,058,510,685\", \"$1…\n$ price      &lt;chr&gt; \"$54,373.45\", \"$2,871.28\", \"$0.9996\", \"$469.29\", \"$125.54\",…\n\n\n\nIs the data structure as expected? From the data which we have above, there are some columns that needs their data types changed. The market_cap and price column should be numeric/double data type and not character.\n\n\n\nShow the code\ncrypto &lt;- crypto |&gt; \n  mutate(\n    market_cap = str_remove_all(market_cap, r\"--[\\$[\\d.]+[TB]]--\"),\n    market_cap = parse_number(market_cap),\n    price = parse_number(price)\n  )\n\nstr(crypto)\n\n\ntibble [200 × 4] (S3: tbl_df/tbl/data.frame)\n $ name      : chr [1:200] \"BTCBitcoin\" \"ETHEthereum\" \"USDTTether USDt\" \"BNBBNB\" ...\n $ symbol    : chr [1:200] \"BTC\" \"ETH\" \"USDT\" \"BNB\" ...\n $ market_cap: num [1:200] 1.07e+12 3.45e+11 1.12e+11 6.92e+10 5.81e+10 ...\n $ price     : num [1:200] 54373 2871 1 469 126 ..."
  },
  {
    "objectID": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html#handling-missing-data",
    "href": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html#handling-missing-data",
    "title": "Webscraping and Visualizing the Top CryptoCurrencies",
    "section": "Handling missing Data",
    "text": "Handling missing Data\n\nI used the skimr package to identify missing data. The code then filtered the crypto data frame to keep only complete rows with values in all columns.\n\n\n\nShow the code\nskimr::n_missing(crypto)\n\n\n[1] 360\n\n\n\n\nShow the code\nskimr::skim(crypto)\n\n\n\nData summary\n\n\nName\ncrypto\n\n\nNumber of rows\n200\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nname\n0\n1\n3\n37\n0\n200\n0\n\n\nsymbol\n0\n1\n0\n4\n180\n21\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nmarket_cap\n180\n0.1\n9.107187e+10\n2.433057e+11\n4359885722\n6.659552e+09\n1.119664e+10\n3.93483e+10\n1.071480e+12\n▇▁▁▁▁\n\n\nprice\n180\n0.1\n2.912640e+03\n1.212951e+04\n0\n8.500000e-01\n5.540000e+00\n7.51500e+01\n5.437345e+04\n▇▁▁▁▁\n\n\n\n\n\n\n\nShow the code\ncrypto &lt;- crypto[complete.cases(crypto), ]\nskimr::skim_without_charts(crypto)\n\n\n\nData summary\n\n\nName\ncrypto\n\n\nNumber of rows\n20\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nname\n0\n1\n6\n17\n0\n20\n0\n\n\nsymbol\n0\n1\n3\n4\n0\n20\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\n\n\n\n\nmarket_cap\n0\n1\n9.107187e+10\n2.433057e+11\n4359885722\n6.659552e+09\n1.119664e+10\n3.93483e+10\n1.071480e+12\n\n\nprice\n0\n1\n2.912640e+03\n1.212951e+04\n0\n8.500000e-01\n5.540000e+00\n7.51500e+01\n5.437345e+04"
  },
  {
    "objectID": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html#crytocurrencies-by-market-capitalization",
    "href": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html#crytocurrencies-by-market-capitalization",
    "title": "Webscraping and Visualizing the Top CryptoCurrencies",
    "section": "Crytocurrencies by Market Capitalization",
    "text": "Crytocurrencies by Market Capitalization\n\n\nShow the code\nggplot(\n  crypto_summary,\n  aes(xmin = 3, xmax = 4,ymin = ymin, ymax = ymax, fill = new_sym)\n) +\n  geom_rect() +\n  expand_limits(x = c(1.5, 4)) +\n  coord_polar(theta = \"y\", start = 1) +\n  scale_fill_brewer(palette =\"YlOrRd\") +\n  theme_void() +\n  ggrepel::geom_label_repel(\n    x = 3,\n    aes(y = lab_pos, label = label),\n    size = 2,\n    col = \"gray3\"\n  ) +\n  theme_void() +\n  ggtitle(\"Market Cap of Top Cryptocurrencies\") +\n  theme(\n    legend.position = \"none\"\n  )\n\n\n\n\n\nCrypto Asset Market Cap\n\n\n\n\nAs shown in ?@fig-market-cap, Bitcoin, and ETH are clearly dominating the crypto space in market capitalization. Assets such as BNB, SOL and USDT are slowly increasing their dominance ranging from 3 - 6%."
  },
  {
    "objectID": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html#top-20-cryptocurrencies-price",
    "href": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html#top-20-cryptocurrencies-price",
    "title": "Webscraping and Visualizing the Top CryptoCurrencies",
    "section": "Top 20 Cryptocurrencies Price",
    "text": "Top 20 Cryptocurrencies Price\n\nI downloaded logos for the top 20 cryptocurrencies and added them as an “images” column to the data frame.\nThe code then creates a bar chart to visualize individual cryptocurrency prices, with labels indicating the price for each currency.\n\n\n\nShow the code\nimages &lt;- list.files(path = \"images\", full.names = TRUE)\n\ncrypto &lt;- crypto |&gt; \n  arrange(symbol) |&gt; \n  bind_cols(\"images\" = images)\n\ncrypto_img &lt;- crypto |&gt; \n  mutate(\n    images = paste0(\"&lt;img src='\", images, \"' width='15'/&gt;\")\n  )\n\n\nNow we can visualize the prices of each asset.\n\n\nShow the code\ncrypto_img |&gt; \n  ggplot(aes(price, fct_reorder(images, price))) +\n  geom_col(\n    width = .1,\n    fill = \"#FBD25B\"\n  ) +\n  geom_label(\n    aes(label = round(price, 2)),\n    col = \"white\",\n    fill = \"#AE1D0E\",\n    size = 2.5\n  ) +\n  labs(\n    title = \"Price of the Top 20 Cryptocurrencies\"\n  ) +\n  scale_x_log10(label = scales::label_number()) +\n  theme_minimal() +\n  theme(\n    axis.text.y = ggtext::element_markdown(),\n    axis.text.x = element_blank(),\n    axis.ticks = element_blank(),\n    axis.title = element_blank(),\n    plot.title = element_text(hjust = .5, color = \"#AE1D0E\")\n  )"
  },
  {
    "objectID": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html#conclusion",
    "href": "posts/webscraping-and-visualizing-the-top-crypto-currencies/index.html#conclusion",
    "title": "Webscraping and Visualizing the Top CryptoCurrencies",
    "section": "Conclusion",
    "text": "Conclusion\n\nIn this project, I successfully scraped cryptocurrency data, cleaned it for analysis, and created visualizations to explore market cap distribution and individual cryptocurrency prices. This process demonstrates the power of web scraping and data visualization in R."
  },
  {
    "objectID": "posts/possum regression/index.html",
    "href": "posts/possum regression/index.html",
    "title": "How old is that Possum?",
    "section": "",
    "text": "This project aims to predict the age of possums collected from three different sites in Australia. The sites are Victoria, New South Wales and Queensland. New South Wales and Queensland are compressed into a single category “Others”. The data is available in the DAAG R package developed by Maindonald, Braun, and Braun (2015).\n\n\n\nCute Possum\n\n\nThe data is having the following properties:\n\n\n\n\n\n\n\n\nS/N\nVariable name\nDefinition\n\n\n\n\n1.\ncase\nObservation number\n\n\n2.\nsite\nThe site number where the possum was trapped.\n\n\n3.\nPop\nThe site as Vic (Victoria) or Other (New South Wales and Queensland)\n\n\n4.\nsex\nGender, either m (male) or f (female).\n\n\n5.\nage\nAge of possum\n\n\n6.\nhdlngth\nHead length, in mm.\n\n\n7.\nskullw\nSkull width, in mm.\n\n\n8.\ntotlngth\nTotal length, in cm.\n\n\n9.\ntaill\nTail length, in cm.\n\n\n10.\nfootlgth\nFoot length in mm\n\n\n11.\nearconch\nEar conch length in mm\n\n\n12.\neye\ndistance from medial canthus to lateral canthus of right eye\n\n\n13.\nchest\nchest girth (in cm)\n\n\n14.\nbelly\nbelly girth (in cm)\n\n\n\n\n\n\n\nShow the code\npsm &lt;- DAAG::possum |&gt; janitor::clean_names() |&gt; \n  remove_rownames() |&gt; as_tibble()\n\n\nAfter getting any data, the first thing to do is trying to understand the data\n\n\nShow the code\nskimr::skim_without_charts(psm)\n\n\n\n\nTable 1: Summary statistics of possum data\n\n\n\n\n\n\n(a)\n\n\n\n\n\nName\npsm\n\n\nNumber of rows\n104\n\n\nNumber of columns\n14\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n2\n\n\nnumeric\n12\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\n\n\n\nVariable type: factor\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\npop\n0\n1\nFALSE\n2\noth: 58, Vic: 46\n\n\nsex\n0\n1\nFALSE\n2\nm: 61, f: 43\n\n\n\n\n\n\nVariable type: numeric\n\n\n\n(c)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\n\n\n\n\ncase\n0\n1.00\n52.50\n30.17\n1.0\n26.75\n52.50\n78.25\n104.0\n\n\nsite\n0\n1.00\n3.62\n2.35\n1.0\n1.00\n3.00\n6.00\n7.0\n\n\nage\n2\n0.98\n3.83\n1.91\n1.0\n2.25\n3.00\n5.00\n9.0\n\n\nhdlngth\n0\n1.00\n92.60\n3.57\n82.5\n90.68\n92.80\n94.73\n103.1\n\n\nskullw\n0\n1.00\n56.88\n3.11\n50.0\n54.98\n56.35\n58.10\n68.6\n\n\ntotlngth\n0\n1.00\n87.09\n4.31\n75.0\n84.00\n88.00\n90.00\n96.5\n\n\ntaill\n0\n1.00\n37.01\n1.96\n32.0\n35.88\n37.00\n38.00\n43.0\n\n\nfootlgth\n1\n0.99\n68.46\n4.40\n60.3\n64.60\n68.00\n72.50\n77.9\n\n\nearconch\n0\n1.00\n48.13\n4.11\n40.3\n44.80\n46.80\n52.00\n56.2\n\n\neye\n0\n1.00\n15.05\n1.05\n12.8\n14.40\n14.90\n15.72\n17.8\n\n\nchest\n0\n1.00\n27.00\n2.05\n22.0\n25.50\n27.00\n28.00\n32.0\n\n\nbelly\n0\n1.00\n32.59\n2.76\n25.0\n31.00\n32.50\n34.12\n40.0\n\n\n\n\n\n\n\n\n\n\n\nTable 1 (a) shows that data was collected on 104 possum’s. There are 2 categorical variables, pop and sex, but this should be three as site should also be a categorical variable (check below to see transformation of this variable). The case variable is not needed and can be removed. There are missing data in age and footlgth variables, Table 1 (b). We can remove this missing data points as it’s not a lot, Figure 1.\n\n\nShow the code\nvisdat::vis_miss(psm)\n\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\n\n\nShow the code\npsm &lt;- psm |&gt; \n  drop_na() |&gt; \n  select(-case) |&gt; \n  mutate(\n    site = factor(\n      site, \n      levels= 1:7,\n      labels = c(\"Cambarville\", \"Bellbird\", \"Whian Whian\",\n                \"Byrangery\", \"Conondale\", \"Allyn River\", \"Bulburin\")\n    )\n  )"
  },
  {
    "objectID": "posts/possum regression/index.html#loading-the-data",
    "href": "posts/possum regression/index.html#loading-the-data",
    "title": "How old is that Possum?",
    "section": "",
    "text": "Show the code\npsm &lt;- DAAG::possum |&gt; janitor::clean_names() |&gt; \n  remove_rownames() |&gt; as_tibble()\n\n\nAfter getting any data, the first thing to do is trying to understand the data\n\n\nShow the code\nskimr::skim_without_charts(psm)\n\n\n\n\nTable 1: Summary statistics of possum data\n\n\n\n\n\n\n(a)\n\n\n\n\n\nName\npsm\n\n\nNumber of rows\n104\n\n\nNumber of columns\n14\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n2\n\n\nnumeric\n12\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\n\n\n\nVariable type: factor\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\npop\n0\n1\nFALSE\n2\noth: 58, Vic: 46\n\n\nsex\n0\n1\nFALSE\n2\nm: 61, f: 43\n\n\n\n\n\n\nVariable type: numeric\n\n\n\n(c)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\n\n\n\n\ncase\n0\n1.00\n52.50\n30.17\n1.0\n26.75\n52.50\n78.25\n104.0\n\n\nsite\n0\n1.00\n3.62\n2.35\n1.0\n1.00\n3.00\n6.00\n7.0\n\n\nage\n2\n0.98\n3.83\n1.91\n1.0\n2.25\n3.00\n5.00\n9.0\n\n\nhdlngth\n0\n1.00\n92.60\n3.57\n82.5\n90.68\n92.80\n94.73\n103.1\n\n\nskullw\n0\n1.00\n56.88\n3.11\n50.0\n54.98\n56.35\n58.10\n68.6\n\n\ntotlngth\n0\n1.00\n87.09\n4.31\n75.0\n84.00\n88.00\n90.00\n96.5\n\n\ntaill\n0\n1.00\n37.01\n1.96\n32.0\n35.88\n37.00\n38.00\n43.0\n\n\nfootlgth\n1\n0.99\n68.46\n4.40\n60.3\n64.60\n68.00\n72.50\n77.9\n\n\nearconch\n0\n1.00\n48.13\n4.11\n40.3\n44.80\n46.80\n52.00\n56.2\n\n\neye\n0\n1.00\n15.05\n1.05\n12.8\n14.40\n14.90\n15.72\n17.8\n\n\nchest\n0\n1.00\n27.00\n2.05\n22.0\n25.50\n27.00\n28.00\n32.0\n\n\nbelly\n0\n1.00\n32.59\n2.76\n25.0\n31.00\n32.50\n34.12\n40.0\n\n\n\n\n\n\n\n\n\n\n\nTable 1 (a) shows that data was collected on 104 possum’s. There are 2 categorical variables, pop and sex, but this should be three as site should also be a categorical variable (check below to see transformation of this variable). The case variable is not needed and can be removed. There are missing data in age and footlgth variables, Table 1 (b). We can remove this missing data points as it’s not a lot, Figure 1.\n\n\nShow the code\nvisdat::vis_miss(psm)\n\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\n\n\nShow the code\npsm &lt;- psm |&gt; \n  drop_na() |&gt; \n  select(-case) |&gt; \n  mutate(\n    site = factor(\n      site, \n      levels= 1:7,\n      labels = c(\"Cambarville\", \"Bellbird\", \"Whian Whian\",\n                \"Byrangery\", \"Conondale\", \"Allyn River\", \"Bulburin\")\n    )\n  )"
  },
  {
    "objectID": "posts/possum regression/index.html#univariate-analysis---target",
    "href": "posts/possum regression/index.html#univariate-analysis---target",
    "title": "How old is that Possum?",
    "section": "Univariate Analysis - Target",
    "text": "Univariate Analysis - Target\n\n\nShow the code\npsm |&gt; \n  summarize(\n    median_age = median(age),\n    mean_age = round(mean(age), 2),\n    minimum_age = min(age),\n    maximum_age = max(age)\n  ) |&gt; kable(\n    col.names = c(\"Median\", \"Mean\", \"Min\", \"Max\"),\n    align = \"lccr\",\n    caption = \"Measure of Central Tendency for Age\"\n  )\n\n\n\n\nTable 2: Descriptive Statistics for Possum Age\n\n\n\n\nMeasure of Central Tendency for Age\n\n\nMedian\nMean\nMin\nMax\n\n\n\n\n3\n3.82\n1\n9\n\n\n\n\n\n\n\n\nTable 2 shows a spread mean and median value for age which might indicates that the distribution is skewed or bimodal, see Figure 2.\n\n\nShow the code\npsm |&gt; \n  ggplot(aes(age)) +\n  geom_density(col = \"#ab2493\") +\n  labs(\n    x = \"Age\",\n    y = \"Density\",\n    title = \"Age variable showing a bimodal distribution\"\n  )\n\n\n\n\n\n\n\n\nFigure 2: Distribution of Age variable"
  },
  {
    "objectID": "posts/possum regression/index.html#univariate-analysis-of-features",
    "href": "posts/possum regression/index.html#univariate-analysis-of-features",
    "title": "How old is that Possum?",
    "section": "Univariate Analysis of Features",
    "text": "Univariate Analysis of Features\n\nFactors\n\nRegions and Sites (Trap Locations)\n\nShow the code\npsm |&gt; \n  mutate(\n    pop = case_when(\n      pop == \"Vic\" ~ \"Victoria\",\n      .default = \"Others\"\n    )\n  ) |&gt; \n  ggplot(aes(pop)) +\n  geom_bar(fill = \"cadetblue4\") +\n  expand_limits(y = c(0, 70)) +\n  labs(\n    x = \"Population\",\n    y = \"Frequency\",\n    title = \"Population of Registered Possums According to Regions\"\n  ) +\n  theme(plot.title = element_text(face = \"bold\", hjust = .5))\n\npsm |&gt; \n  count(site) |&gt; \n  arrange(n) |&gt; \n  ggplot(aes(n, fct_reorder(site, n))) +\n  geom_bar(\n    stat = \"identity\",\n    fill = \"coral2\"\n  ) +\n  labs(\n    y = \"Sites\",\n    x = \"Count\",\n    title = \"Population of Registered Possums According to Sites\"\n  ) +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = .5)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\nFigure 3: Registered Possum Population Record\n\n\n\nMore possums were recorded at the region labelled Other Figure 3. We should recall that Other is the combination of records from New South Wales and Queensland. For the sites where trap where placed within the regions, Cambarville have the highest record of possums with more than half the second site, Bulburin.\n\n\n\nNumerical Variables\n\n\nShow the code\npsm_long &lt;- psm |&gt; \n  pivot_longer(\n    cols = hdlngth:belly,\n    names_to = \"variables\",\n    values_to = \"values\"\n  )\n\npsm_long |&gt; \n  summarize(\n    .by = variables,\n    mean = mean(values),\n    median = median(values),\n    minimum = min(values),\n    maximum = max(values)\n  ) |&gt; \n  kable(\n    col.names = c(\"Variable\", \"Mean\", \"Median\", \"Minimum\", \"Maximum\"),\n    align = \"lcccr\"\n  )\n\n\n\n\nTable 3: Measure of Central Tendency for Numerical Variable\n\n\n\n\n\n\nVariable\nMean\nMedian\nMinimum\nMaximum\n\n\n\n\nhdlngth\n92.73069\n92.9\n82.5\n103.1\n\n\nskullw\n56.96040\n56.4\n50.0\n68.6\n\n\ntotlngth\n87.26931\n88.0\n75.0\n96.5\n\n\ntaill\n37.04951\n37.0\n32.0\n43.0\n\n\nfootlgth\n68.39802\n67.9\n60.3\n77.9\n\n\nearconch\n48.13366\n46.8\n41.3\n56.2\n\n\neye\n15.05049\n14.9\n12.8\n17.8\n\n\nchest\n27.06436\n27.0\n22.0\n32.0\n\n\nbelly\n32.63861\n32.5\n25.0\n40.0\n\n\n\n\n\n\n\n\nTable 3 shows the measure of central tendency. The difference between median and mean is minimal indicating a normal distribution.\n\n\nShow the code\nadditional_colors &lt;- c(\"#af4242\", \"#535364\", \"#FFC300\")\nset_swatch(c(unique(swatch()), additional_colors))\n\npsm_long |&gt; \n  ggplot(aes(values, col = variables)) +\n  geom_density() +\n  scale_color_discrete() +\n  facet_wrap(~variables, scales = \"free\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nFigure 4: Numerical variable distribution\n\n\n\n\n\nAll the numerical variables are normally distributed Figure 4. earconch, footlgth, taill, and totlngth are bimodals."
  },
  {
    "objectID": "posts/possum regression/index.html#multivariate-analysis",
    "href": "posts/possum regression/index.html#multivariate-analysis",
    "title": "How old is that Possum?",
    "section": "Multivariate Analysis",
    "text": "Multivariate Analysis\n\n\nShow the code\npsm |&gt;\n  mutate(\n    pop = case_when(\n      pop == \"Vic\" ~ \"Victoria\",\n      .default = \"Others\"\n    )\n  ) |&gt; \n  ggplot(aes(site, age, fill = pop, col = \"#000\")) +\n  geom_violin(inherit.aes = FALSE, aes(site, age)) +\n  geom_boxplot(position = \"dodge\", width = .2) +\n  geom_jitter(size = .5) +\n  facet_wrap(~pop, scales = \"free\") +\n  coord_flip() +\n  theme(legend.position = \"none\")\n\n\nWarning: The `scale_name` argument of `discrete_scale()` is deprecated as of ggplot2\n3.5.0.\n\n\n\n\n\n\n\n\n\n\nCorrelation Matrix\n\n\nShow the code\nggcorr(\n  psm,\n  geom = \"text\",\n  low = \"#219123\",\n  mid = \"#e09263\",\n  high = \"#8f0123\"\n)\n\n\n\n\n\n\n\n\nFigure 5: Correlation Matrix\n\n\n\n\n\nThe correlation of the variables to age is low with the maximum correlation being with belly, Figure 5. However, there’s high correlation between the predictors and to prevent collinearity we could consider employing Principal Component Analysis to transform correlated predictors to uncorrelated predictor. More information on the relationships existing between the variables can be seen in Figure 6.\n\n\nShow the code\nggpairs(psm)\n\n\n\n\n\n\n\n\nFigure 6: Generalized pairs plot"
  },
  {
    "objectID": "posts/possum regression/index.html#data-sharing",
    "href": "posts/possum regression/index.html#data-sharing",
    "title": "How old is that Possum?",
    "section": "Data Sharing",
    "text": "Data Sharing\nFigure 2 shows how older possums from age 8 to 9 are not well represented in the data. A stratified data sharing technique will be employed to account for less represented age data point.\n\n\nShow the code\nset.seed(124)\npsm_split &lt;- initial_split(psm, prop = .75, strata = age)\npsm_train &lt;- training(psm_split)\n\n\nIf we check Figure 7, possums that are 8 and 9 years old are represented.\n\n\nShow the code\npsm_train |&gt; \n  count(age) |&gt; \n  ggplot(aes(factor(age), n)) +\n  geom_col() +\n  geom_text(\n    aes(label = n),\n    nudge_y = .5,\n    col = \"red\"\n  ) +\n  labs(\n    x = \"Age\",\n    y = \"Count\",\n    title = \"Age Frequency in Training Data\"\n  )\n\n\n\n\n\n\n\n\nFigure 7: Age data point frequency in training data\n\n\n\n\n\nTo prevent data leaking, the data will be resampled to have a validation-training data in 10 folds using the k-folds resampling.\n\n\nShow the code\nset.seed(124)\npsm_folds &lt;- vfold_cv(psm_train, v = 10)"
  },
  {
    "objectID": "posts/possum regression/index.html#model-specification",
    "href": "posts/possum regression/index.html#model-specification",
    "title": "How old is that Possum?",
    "section": "Model Specification",
    "text": "Model Specification\nWe will use linear regression to predict the age of possums\n\n\nShow the code\nlm_spec &lt;- linear_reg() |&gt; \n  set_engine(\"lm\")\nlm_spec |&gt; translate()\n\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\nModel fit template:\nstats::lm(formula = missing_arg(), data = missing_arg(), weights = missing_arg())"
  },
  {
    "objectID": "posts/possum regression/index.html#feature-engineering",
    "href": "posts/possum regression/index.html#feature-engineering",
    "title": "How old is that Possum?",
    "section": "Feature engineering",
    "text": "Feature engineering\nThree preprocessing will be added to formular specification. These are:\n\nNormalizing, centering and scaling numerical variables\nPCA to reduce collinearity between numeric variables\nCreating dummy variables for categorical data.\n\nThese preprocesses are added as presented down to the last step which is creating dummy variables for categorical data.\n\n\nShow the code\npsm_rec_1 &lt;- recipe(age ~ ., data = psm_train)\n\npsm_rec_2 &lt;- psm_rec_1 |&gt; \n  step_normalize(all_numeric_predictors()) |&gt; \n  step_center(all_numeric_predictors()) |&gt; \n  step_scale(all_numeric_predictors())\n\npsm_rec_3 &lt;- psm_rec_2 |&gt; \n  step_pca(all_numeric_predictors())\n\npsm_rec_4 &lt;- psm_rec_3 |&gt;\n  step_dummy(all_factor_predictors()) \n\n\nThe result from applying the whole steps is shown in Table 4\n\n\nShow the code\npsm_rec_4 |&gt; \n  prep() |&gt; \n  juice() |&gt; \n  kable()\n\n\n\n\nTable 4: Data look after preprocessing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nage\nPC1\nPC2\nPC3\nPC4\nPC5\nsite_Bellbird\nsite_Whian.Whian\nsite_Byrangery\nsite_Conondale\nsite_Allyn.River\nsite_Bulburin\npop_other\nsex_m\n\n\n\n\n2\n-0.0683403\n-1.3430047\n0.1629385\n-0.3007284\n-0.5391333\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0.5255119\n-2.0477985\n-0.8395109\n0.1766334\n-0.0667790\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2\n0.5932377\n-1.9591624\n0.3740650\n0.6887651\n0.0693626\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n2\n-0.2120375\n-2.2111365\n1.7088223\n-0.3387357\n-0.0931182\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n2\n-2.7210452\n-1.3894871\n0.2290110\n0.7561382\n1.2385934\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2\n-1.6707158\n-1.6525644\n0.3608677\n-0.3541424\n-0.3539676\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2\n-1.3813568\n-1.6981681\n-0.0280696\n0.7534030\n0.9919553\n1\n0\n0\n0\n0\n0\n0\n1\n\n\n2\n-1.5913442\n-1.8659808\n-0.8607981\n-0.6136969\n-0.3717057\n1\n0\n0\n0\n0\n0\n0\n0\n\n\n2\n-1.8079989\n-2.3782409\n-0.8116058\n-2.0083817\n-0.0033699\n1\n0\n0\n0\n0\n0\n0\n0\n\n\n2\n-1.1954515\n0.8971959\n-0.0703966\n0.7598542\n-0.3683068\n0\n1\n0\n0\n0\n0\n1\n1\n\n\n2\n4.1803713\n0.8897649\n0.3938191\n-1.1044746\n0.7567941\n0\n0\n1\n0\n0\n0\n1\n1\n\n\n2\n4.6163778\n0.9891800\n-1.6076608\n-0.4016217\n0.8022071\n0\n0\n1\n0\n0\n0\n1\n1\n\n\n1\n-4.0340944\n0.7906070\n-0.4034363\n-0.8853157\n-0.3652180\n0\n0\n0\n1\n0\n0\n1\n1\n\n\n1\n-4.1822396\n0.7403597\n1.4657432\n0.7862599\n-0.0250014\n0\n0\n0\n1\n0\n0\n1\n1\n\n\n1\n-4.8749934\n1.0799429\n0.5352953\n0.7612442\n-0.0609334\n0\n0\n0\n0\n1\n0\n1\n1\n\n\n2\n2.5067698\n1.2854692\n-0.6829234\n1.2902829\n0.2988343\n0\n0\n0\n0\n0\n1\n1\n1\n\n\n2\n-1.5370018\n0.2066507\n-0.2442228\n0.0557942\n0.3654421\n0\n0\n0\n0\n0\n1\n1\n1\n\n\n1\n-3.2753856\n0.2501520\n0.5857415\n0.1900539\n1.4760626\n0\n0\n0\n0\n0\n1\n1\n1\n\n\n1\n-2.1384046\n0.7896655\n-0.8456387\n0.4282661\n-0.8568027\n0\n0\n0\n0\n0\n1\n1\n1\n\n\n3\n1.1122517\n-1.7400213\n0.1350000\n0.5145977\n0.8017867\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n3\n2.4376323\n-0.1537461\n0.5696070\n0.9282523\n-0.5959512\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n3\n2.1208772\n-1.2766662\n-0.5393494\n-0.7589132\n-0.3098302\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n3\n-0.8479812\n-1.9954784\n-0.1869869\n0.7504195\n0.5086049\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n-0.2546200\n-0.7339399\n-0.5724089\n1.2923626\n0.3215358\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n3\n-1.3035647\n-0.9059791\n0.2567987\n1.5597938\n0.6757254\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n3\n-1.3801925\n-1.7109431\n-0.8450879\n0.1415803\n0.4597025\n1\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n-1.4546803\n-2.2008308\n0.3436864\n-0.9008104\n-0.1966397\n1\n0\n0\n0\n0\n0\n0\n1\n\n\n3\n0.5475648\n1.2161183\n1.0312910\n0.5588546\n0.0878335\n0\n1\n0\n0\n0\n0\n1\n0\n\n\n3\n2.2170891\n0.9836707\n0.7951650\n0.1065218\n1.8105991\n0\n0\n1\n0\n0\n0\n1\n1\n\n\n3\n1.9972559\n1.1700952\n-1.4558448\n-0.9730381\n1.0159799\n0\n0\n1\n0\n0\n0\n1\n1\n\n\n3\n-0.0160895\n2.2457175\n0.2960816\n0.3467818\n0.4165286\n0\n0\n0\n1\n0\n0\n1\n0\n\n\n3\n-0.2223062\n2.0686619\n1.3282648\n-0.4517102\n-1.1944972\n0\n0\n0\n0\n1\n0\n1\n1\n\n\n3\n-3.3732068\n0.9325033\n-0.5077306\n-0.6443673\n0.5400554\n0\n0\n0\n0\n1\n0\n1\n0\n\n\n3\n-0.4720101\n1.8872613\n-1.1706750\n1.3286723\n0.2507486\n0\n0\n0\n0\n1\n0\n1\n1\n\n\n3\n-2.5900211\n1.6833673\n-1.5180662\n0.4190351\n-0.2681204\n0\n0\n0\n0\n1\n0\n1\n0\n\n\n3\n0.5445663\n0.8323311\n-0.1462565\n-0.0678134\n1.1252436\n0\n0\n0\n0\n0\n1\n1\n1\n\n\n3\n-3.1702672\n0.7865104\n-1.6716095\n0.1959689\n-0.0137905\n0\n0\n0\n0\n0\n1\n1\n1\n\n\n3\n-2.0113676\n0.9835760\n-0.4212246\n0.6511830\n-0.2093714\n0\n0\n0\n0\n0\n1\n1\n1\n\n\n3\n-0.1882476\n1.3519467\n-1.4211159\n-0.4945806\n-0.7699330\n0\n0\n0\n0\n0\n1\n1\n0\n\n\n5\n0.8018678\n-1.1017884\n0.1905308\n0.3472246\n0.0514925\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n5\n0.8585521\n-0.4801589\n0.7640545\n-0.2147241\n0.9196030\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n5\n0.2620327\n-1.2163951\n0.8313169\n-1.1950904\n-0.8132611\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n4\n-0.5062891\n-1.8550529\n-0.2235993\n-0.4786062\n-0.0109695\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n4\n1.2896934\n-0.8353170\n0.3121114\n0.8084280\n-0.9564098\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n4\n0.7633360\n-1.4221693\n0.3320057\n0.2360456\n-0.9218318\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n4\n1.7348293\n-0.7827117\n-0.5492365\n1.5939574\n-0.1108831\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n4\n1.0074512\n-1.4392717\n1.4124102\n-0.6572234\n-0.9983031\n1\n0\n0\n0\n0\n0\n0\n1\n\n\n4\n1.2196798\n0.7318619\n0.3807984\n-1.4813922\n-0.5696577\n0\n1\n0\n0\n0\n0\n1\n1\n\n\n5\n0.1624015\n0.9176772\n-0.6018114\n-0.2048875\n-1.2980099\n0\n1\n0\n0\n0\n0\n1\n0\n\n\n5\n1.2769012\n1.7340403\n1.7505303\n-1.9506005\n-1.4972834\n0\n1\n0\n0\n0\n0\n1\n0\n\n\n4\n2.8730337\n1.7649283\n-1.8840529\n-0.0327439\n-1.4752294\n0\n0\n1\n0\n0\n0\n1\n0\n\n\n4\n-0.7811046\n1.2505268\n1.2772509\n-0.8895713\n0.9844815\n0\n0\n0\n1\n0\n0\n1\n1\n\n\n5\n-0.1778915\n1.8234918\n1.8421001\n0.2472064\n0.7975054\n0\n0\n0\n1\n0\n0\n1\n1\n\n\n5\n0.5870791\n0.9806575\n-0.4520133\n-0.5907173\n-0.2002764\n0\n0\n0\n1\n0\n0\n1\n1\n\n\n4\n-2.2936714\n1.2946467\n-0.3851774\n0.0574455\n-1.6155298\n0\n0\n0\n0\n1\n0\n1\n0\n\n\n5\n0.3984752\n2.4505759\n1.9146399\n1.2545626\n-0.3336188\n0\n0\n0\n0\n1\n0\n1\n1\n\n\n4\n-2.9202721\n1.6366815\n0.3851973\n-0.6849716\n-0.9226780\n0\n0\n0\n0\n1\n0\n1\n0\n\n\n5\n0.6367704\n0.7329147\n-0.5223680\n-3.1495636\n1.8185866\n0\n0\n0\n0\n0\n1\n1\n1\n\n\n8\n1.7826009\n-1.6838293\n0.1706863\n-0.2690101\n-0.4859142\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n6\n1.1123234\n-0.7925447\n0.6658510\n0.3974655\n-0.0097557\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n6\n2.8417842\n-0.6314935\n-0.3153884\n1.0465569\n0.2123617\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n6\n1.4913213\n-1.1741720\n-0.0838276\n1.1679075\n-0.2170689\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n6\n1.4425787\n-1.4133157\n-0.7059632\n0.3147806\n-0.1514926\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n9\n0.9480141\n-1.0555139\n0.2764188\n0.8208403\n-0.1018660\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n6\n0.2688303\n-1.0311888\n-0.6140051\n0.6025036\n0.2966715\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n7\n2.3860203\n-1.8788997\n-0.1915698\n-0.3147883\n-1.2298158\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n7\n0.6864520\n-1.5752069\n0.2795289\n-0.1682235\n-0.4540231\n1\n0\n0\n0\n0\n0\n0\n1\n\n\n7\n-1.4194670\n-0.5106128\n1.2546762\n-0.9316148\n0.3494254\n1\n0\n0\n0\n0\n0\n0\n1\n\n\n6\n2.1555615\n1.8143879\n-0.1552479\n0.3237445\n1.1957884\n0\n1\n0\n0\n0\n0\n1\n1\n\n\n7\n3.9328351\n2.3307182\n0.9015280\n0.5265040\n-0.2550755\n0\n0\n1\n0\n0\n0\n1\n1\n\n\n7\n-0.8366410\n0.9049272\n-2.1111769\n-0.2795170\n-0.3564392\n0\n0\n0\n1\n0\n0\n1\n0\n\n\n6\n0.4252388\n2.0484319\n-0.7460744\n0.3875539\n-0.1874486\n0\n0\n0\n1\n0\n0\n1\n1\n\n\n6\n0.4202458\n1.4909987\n1.4297284\n0.2056943\n0.0191890\n0\n0\n0\n0\n1\n0\n1\n1\n\n\n6\n-0.2551146\n0.1745767\n-0.5514308\n-1.9875642\n1.1766109\n0\n0\n0\n0\n0\n1\n1\n1\n\n\n\n\n\n\n\n\nThe numerical predictors has been reduced to 5 variables."
  },
  {
    "objectID": "posts/possum regression/index.html#model-workflow",
    "href": "posts/possum regression/index.html#model-workflow",
    "title": "How old is that Possum?",
    "section": "Model Workflow",
    "text": "Model Workflow\n\n\nShow the code\npsm_wf_set &lt;- workflow_set(\n  preproc = list(\n    \"formula\" = psm_rec_1,\n    \"normalized\" = psm_rec_2, \n    \"pca\" = psm_rec_3,\n    \"dummy\" = psm_rec_4\n  ),\n  models = list(\"ols\" = lm_spec),\n  cross = TRUE\n)\n\npsm_wf_set\n\n\n# A workflow set/tibble: 4 × 4\n  wflow_id       info             option    result    \n  &lt;chr&gt;          &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n1 formula_ols    &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n2 normalized_ols &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n3 pca_ols        &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n4 dummy_ols      &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n\n\n\nFitting the model\n\n\nShow the code\npsm_mod &lt;- psm_wf_set |&gt; \n  workflow_map(\n    \"fit_resamples\",\n    resamples = psm_folds,\n    seed = 124\n)\n\ncollect_metrics(psm_mod) |&gt; kable()\n\n\n\n\nTable 5: Model metric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwflow_id\n.config\npreproc\nmodel\n.metric\n.estimator\nmean\nn\nstd_err\n\n\n\n\nformula_ols\nPreprocessor1_Model1\nrecipe\nlinear_reg\nrmse\nstandard\n1.7863370\n10\n0.1001647\n\n\nformula_ols\nPreprocessor1_Model1\nrecipe\nlinear_reg\nrsq\nstandard\n0.2506679\n10\n0.0642785\n\n\nnormalized_ols\nPreprocessor1_Model1\nrecipe\nlinear_reg\nrmse\nstandard\n1.7863370\n10\n0.1001647\n\n\nnormalized_ols\nPreprocessor1_Model1\nrecipe\nlinear_reg\nrsq\nstandard\n0.2506679\n10\n0.0642785\n\n\npca_ols\nPreprocessor1_Model1\nrecipe\nlinear_reg\nrmse\nstandard\n1.7590867\n10\n0.1122277\n\n\npca_ols\nPreprocessor1_Model1\nrecipe\nlinear_reg\nrsq\nstandard\n0.1970622\n10\n0.0555754\n\n\ndummy_ols\nPreprocessor1_Model1\nrecipe\nlinear_reg\nrmse\nstandard\n1.7590867\n10\n0.1122277\n\n\ndummy_ols\nPreprocessor1_Model1\nrecipe\nlinear_reg\nrsq\nstandard\n0.1970622\n10\n0.0555754\n\n\n\n\n\n\n\n\nTable 5 shows no difference in the model between dummy_ols and pca_ols which is different from using the formula without preprocessing, formula_ols and normalized_ols. This presented visually in Figure 8\n\n\nShow the code\ncollect_metrics(psm_mod) |&gt; \n  filter(.metric == \"rmse\") |&gt; \n  select(wflow_id, mean, std_err) |&gt; \n  mutate(\n    ymax = mean + std_err,\n    ymin = mean - std_err\n  ) |&gt; \n  ggplot(aes(wflow_id, mean, col = wflow_id)) +\n  geom_pointrange(aes(ymin = ymin, ymax =ymax)) +\n  labs(\n    x = \"Preproc\",\n    title = \"RMSE of Possum Linear Regression Model for 3 Preprocessor\"\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nFigure 8: Model evaluation using RMSE for each preprocessor\n\n\n\n\n\nWe can use either of pca_ols or dummy_ols as they have the lowest mean.\n\n\nShow the code\npsm_pca_mod &lt;- psm_mod |&gt; \n  extract_workflow(id = \"pca_ols\")\n\npsm_pca_mod \n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n4 Recipe Steps\n\n• step_normalize()\n• step_center()\n• step_scale()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\n\n\nShow the code\npsm_model &lt;- last_fit(\n  psm_pca_mod,\n  split = psm_split\n)\n\n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\n\n\nShow the code\npsm_model |&gt; \n  collect_predictions() |&gt; \n  select(\"prediction\" =.pred, age) |&gt; \n  mutate(\n    prediction = ceiling(prediction),\n    residual = age - prediction\n  ) |&gt; \n  ggplot(\n    aes(age, residual)\n  ) +\n  geom_point() +\n  geom_hline(aes(yintercept = 0), col = \"gray3\") +\n  ggtitle(\"Residual\")\n\n\n\n\n\n\n\n\n\nWhile the points are fairly distributed along the y axis and x axis, the effect of having little representative from the population for old-aged possum, age 9 and 8 can be see. The lack of points on the lower-right side of the plot is a good of indication."
  },
  {
    "objectID": "posts/possum regression/index.html#feature-importance",
    "href": "posts/possum regression/index.html#feature-importance",
    "title": "How old is that Possum?",
    "section": "Feature Importance",
    "text": "Feature Importance\nThe features contributing the most to the model are shown in Figure 9\n\n\nShow the code\npsm_model |&gt;\n  extract_fit_parsnip() |&gt; \n  vip::vip(\n    num_features = 10,\n    geom = \"col\"\n  ) +\n  ggtitle(\"Feature Importance\")\n\n\n\n\n\n\n\n\nFigure 9: PC1, and Byrangery sites are the most important variables."
  },
  {
    "objectID": "posts/possum regression/index.html#summary",
    "href": "posts/possum regression/index.html#summary",
    "title": "How old is that Possum?",
    "section": "Summary",
    "text": "Summary\nWhile this a good use of linear regression, the robustness of the model would have been helped if underrepresented data points are available. By the time of writing this blog post, the author with intentions to use only SLR is having no feature engineering method to account for the age variable that has been discretized. A resampling technique such as Monte Carlo or bootstrapping is an approach that could help with the model rather than the use of k-fold resampling method."
  }
]