---
title: "Managing Workflowset Models"
subtitle: "Using **option-add** to Tune Different Model of Workflowset"
date: "2024-05-06"
categories: [Machine Learning, Tuning]
cache: true
code-fold: true
code-copy: hover
code-summary: "Show the code"
image: image_2.jpeg
---

## Introduction

![](https://www.tidymodels.org/images/tidymodels.png){width="50%" fig-align="center"}

The **tidymodels** package is a game-changer for the R ecosystem, providing a streamlined and intuitive approach to modeling. Built on the tidyverse foundation, it offers a cohesive framework that simplifies the journey from data wrangling to robust models. What makes `tidymodels` stand out is its consistent workflow, reducing the learning curve for data scientists and ensuring compatibility across different modeling packages【@kuhn2022tidy】.

### Workflow

The `workflows` package is one of the standout components of tidymodels, making the iterative machine learning process in R more manageable. By bundling model fitting and data preprocessing steps into a single coherent object, `workflows` simplifies the complexities of the machine learning pipeline, ensuring each step is clearly defined and reproducible. This iterative machine learning process, as covered in "Tidy Modeling with R"【@kuhn2022tidy】, is illustrated below:

![Source: Tidy Modeling with R](https://www.tmwr.org/premade/modeling-process.svg)

### Workflowsets

The focus of this post, the `workflowsets` package, builds on the `workflows` package by extending its capabilities to handle multiple machine learning models. Since the best model for any given task is not predetermined, it's crucial to test multiple models and compare their performances. `workflowsets` is designed to manage multiple workflows, making it easier to compare different modeling approaches and preprocessing strategies.

This blog post introduces the `option_add` function of the `workflowsets` package, which is used to control options for evaluating workflow set functions such as `fit_resamples` and `tune_grid`. For more information on this function, refer to the documentation with `?option_add`.

We start by loading the packages we will be using for this post

```{r}
#| label: import-library
#| message: false
#| warning: false
library(pacman)
p_load(tidyverse, tidymodels, gt, finetune, bonsai)
```

For this post we'll use the [**heart disease dataset**](https://www.kaggle.com/datasets/rashadrmammadov/heart-disease-prediction?resource=download) from kaggle.com. A preview of the data is given @tbl-load-dataset

```{r}
#| label: tbl-load-dataset
#| message: false
#| warning: false
#| tbl-cap: Data Preview
heart_disease <- read_csv("heart_disease_dataset.csv")

head(heart_disease) |> 
  gt() |> 
  tab_header(
    title = "Heart Diseases"
  ) |> 
  opt_stylize(
    style = 2, 
    color = "cyan"
  ) |> 
  as_raw_html()
```

## Short EDA

```{r}
#| label: tbl-preview-data
#| tbl-cap: "Quick description of the data"

skimr::skim_without_charts(heart_disease) |> 
  gt() |> 
  tab_spanner(
    label = "Character",
    columns = character.min:character.whitespace
  ) |> 
  tab_spanner(
    label = "Numeric",
    columns = starts_with("numeric")
  ) |> 
  cols_label(
    skim_type ~ "Type",
    skim_variable ~"Variable",
    n_missing ~ "Missing?",
    complete_rate ~ "Complete?",
    character.min ~ "Min",
    character.max ~ "Max",
    character.empty ~ "Empty",
    character.n_unique ~ "Unique",
    character.whitespace ~ "Gap",
    numeric.mean ~ "Mean",
    numeric.sd ~ "SD",
    numeric.p0 ~ "Min",
    numeric.p25 ~ "25%",
    numeric.p50 ~ "Median",
    numeric.p75 ~ "75%",
    numeric.p100 ~ "Max"
  ) |> 
  cols_width(
    skim_type ~ px(80),
    everything() ~ px(70)
  ) |> 
  opt_stylize(
    style = 2,
    color = "cyan",
  ) |> 
  as_raw_html()
```

@tbl-preview-data shows there are no missing values, so we can proceed with our analysis.

Next, we will convert all character variables to factor data types

```{r}
#| label: convert-chr-to-fct

heart_diseases <- heart_disease |> 
  janitor::clean_names() |> 
  mutate(
    across(where(is.character), factor),
    exercise_hours = factor(exercise_hours),
    stress_level = factor(stress_level),
    heart_disease = factor(
      heart_disease, 
      labels = c("No","Yes"),
      levels = c(0, 1)
    )
  )
```

```{r}
#| label: fig-pairs
#| message: false
#| warning: false
#| fig-cap: "Scattered Matrix Plots of variables"

GGally::ggscatmat(
  data = heart_diseases,
  columns = 1:ncol(heart_diseases),
  color = "heart_disease",
  alpha = .3
)
```

```{r}
#| label: fig-corplot
#| message: false
#| warning: false
#| fig-cap: "Correlation plot of numeric variables"
GGally::ggcorr(
  data = heart_diseases,
  columns = 1:ncol(heart_diseases),
  name = expression(rho),
  geom = "circle",
  size = 3,
  min_size = 5,
  max_size = 10,
  angle = -45
) +
  ggtitle("Correlation Plot of Numeric Variables")
```

```{r}
#| label: fig-outcome
#| fig-cap: Frequency of Heart Disease Outcome

heart_diseases |> 
  ggplot(aes(heart_disease, fill = gender)) +
  geom_bar(position = "dodge") +
  labs(
    x = "Heart disease",
    y = "Frequency",
    title = "Heart disease a bit more prevalent in male than females"
  ) +
  ggthemes::scale_fill_fivethirtyeight()
```

We won't spend time on EDA and proceed with our modeling workflow.

## Modeling

### Data Splitting

we will split our data to 75% for training and 25% for testing, using the outcome variable (`heart_disease`) as the strata to ensure a balance split. Additionally, We will create validation folds to evaluate the models.

```{r}
#| label: data-splitting

set.seed(832)
hd_split <- initial_split(heart_diseases, prop = .75, strata = heart_disease)

hd_train <- training(hd_split)
hd_folds <- vfold_cv(hd_train)

head(hd_train) |> 
  gt() |> 
  opt_stylize(
    style = 2,
    color = "cyan"
  ) |> 
  as_raw_html()
```

### Model Specification

We will use two models for our analysis:

-   K-nearest neighbors (KNN) model

-   Generalized linear model (GLM).

```{r}
#| label: model specification

knn_spec <- nearest_neighbor(
  neighbors = tune(),
  weight_func = tune(),
  dist_power = tune()
) |> 
  set_engine("kknn") |> 
  set_mode("classification")

glm_spec <- logistic_reg() |> 
  set_engine("glm", family = stats::binomial(link = "logit")) |> 
  set_mode("classification")
```

Below is the specification we have set for the KNN model:

```{r}
#| label: knn-spc
knn_spec |>  translate()
```

The KNN spec model is having three tuning parameters. For the GLM model we have the following:

```{r}
#| label: glm-spec
glm_spec |> translate()
```

The GLM specification is having no tuning parameter.

As seen in all the model specification above, the formula is missing. We'll determine the formula for all models and the necessary preprocessing/feature engineering options we want to include in the next step using the `recipe` package

### Data Preprocessing

We have three preprocessing specification. The first defines the formula which we will use, the second includes normalizing all numeric predictors, and the final preprocessing step involves creating dummy variables for our categorical variables.

```{r}
#| label: data-preproc
formula <- recipe(
  heart_disease ~ .,
  data = hd_train
)

normalize <- formula |> 
  step_normalize(all_numeric_predictors())

dummy <- normalize |> 
  step_dummy(all_factor_predictors())
```

```{r}
#| label: tbl-preproc-2
#| tbl-cap: Preview of normalized preprocessed data
normalize |> 
  prep() |> 
  juice() |> 
  head() |> 
  gt() |> 
  opt_stylize(
    style = 3,
    color = "cyan"
  )
```

@tbl-preproc-2 previews how the data looks after normalizing, which is the second feature engineering technique. @tbl-preproc-3 shows the data after creating dummy variables categorical variables.

```{r}
#| label: tbl-preproc-3
#| tbl-cap: Preview of dummy + normalized preprocessed data

dummy |> 
  prep() |> 
  juice() |> 
  head() |> 
  gt() |> 
  opt_stylize(
    style = 2,
    color = "cyan"
  ) |> 
  as_raw_html()
```

### Model Workflow Set

```{r}
#| label: model-workflow
hd_wf_set<- workflow_set(
  preproc = list(
    form = formula,
    norm = normalize,
    dum = dummy
  ),
  models = list(
    glm = glm_spec,
    knn = knn_spec
  )
)
```

### Tuning Parameter

Using the `workflowset` function, we've tied three recipe objects to the three different models. The K-nearest neighbor model needs tuning as mentioned earlier.

```{r}
#| label: fig-tune-grid
#| fig-cap: Tuning grids to be used for K-nearest  neighbor model specification
#| fig-subcap: |
#|  - knn regular tune grid
#|  - knn latin hypercube tune grid
set.seed(34443)

knn_grid <- knn_spec |> 
  extract_parameter_set_dials() |> 
  grid_regular(levels = 6)

knn_latin <- knn_spec |> 
  extract_parameter_set_dials() |> 
  grid_latin_hypercube(size = 300)

grid_control <- control_race(
  save_pred = TRUE,
  save_workflow = TRUE
)

knn_grid |> 
  ggplot(aes(dist_power, neighbors, col = weight_func)) +
  geom_point() +
  ggthemes::scale_color_colorblind() +
  labs(
    x = "Minkowski distance",
    y = "Number of Neighbors",
    title = "k-NN Regular Grid"
  ) +
  facet_wrap(~weight_func) +
  theme(
    legend.position = "none"
  )
  
knn_latin |>
  ggplot(aes(dist_power, neighbors, col = weight_func)) +
  geom_point() +
  ggthemes::scale_color_tableau() +
  labs(
    x = "Minkowski distance",
    y = "Number of Neighbors",
    title = "k-NN Latin Hypercube Grid"
  ) +
  facet_wrap(~weight_func) +
  theme(
    legend.position = "none"
  )
```

We set the tuning grid for the model and use the `option_add` function to specify it. We will test two different grid structures as shown in @fig-tune-grid.

## Using `option_add` to Specify Model Grids

We can specify the grid to use for each model using the `option_add` function. Below is an image of `hd_wf_set` that we defined recently, and we will interpret its output.

![Defined workflowset output](no_optn_add.png)

The image above shows that option column is having zero values as well as the results column.

```{r}
#| label: opt-add

hd_tune <- hd_wf_set |> 
  option_add(
    id = "norm_knn",
    grid = knn_grid,
    control = grid_control
  ) |> 
  option_add(
    id = "form_knn",
    grid = knn_grid,
    control = grid_control
  ) |> 
  option_add(
    id = "norm_knn",
    grid = knn_latin,
    control = grid_control
  ) |> 
  option_add(
    id = "form_knn",
    grid = knn_latin,
    control = grid_control
  ) |> 
  option_add(
    id = "dum_knn",
    grid = knn_grid,
    control = grid_control
  ) |> 
  option_add(
    id = "dum_knn",
    grid = knn_latin,
    control = grid_control
  )

```

![Defined workflowset output after options are added](optn_add.png)

After using the `option-add` function, we can see that KNN model specification have two options added to it. We can now proceed to tune our model.

```{r}
#| label: tune-model
doParallel::registerDoParallel(cores = 6)

hd_tune_res <- workflow_map(
 hd_tune ,
 fn = "tune_race_anova",
 resamples = hd_folds,
 seed = 3343,
 verbose = TRUE
)
```

## Tune Result

```{r}
#| label: fig-tune-res
autoplot(hd_tune_res)
```

```{r}
#| label: tune-res
hd_tune_res |> 
  rank_results(rank_metric = "accuracy") |> 
  filter(.metric == "accuracy") |> 
  select(-c(.metric,  preprocessor, model, n)) |> 
  gt() |> 
  cols_label(
    wflow_id = "Model ID",
    .config = "Model Number"
  ) |> 
  opt_stylize(
    style = 2,
    color = "cyan"
  ) |> 
  as_raw_html()
```

Based on the results, it appears that the KNN model with no preprocessing is the best performing model.

## Conclusion

The success of our KNN model, particularly with preprocessing, underscores the critical role of the `option_add` function. By utilizing `option_add`, we efficiently defined and refined our model's tuning grid, allowing us to systematically explore and optimize hyperparameters. This approach not only enhances model performance but also ensures robustness and reliability in our predictive analytics pipeline.
